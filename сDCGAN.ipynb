{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\Anaconda1\\envs\\NN\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "from scipy.misc.pilutil import imresize, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout, Input\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import initializers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 16 * 8, input_dim = latent_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((8, 8, 256)))\n",
    "        \n",
    "        model.add(Conv2DTranspose(512, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(512, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(256, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(128, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(64, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(32, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(16, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(8, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(img_channels, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size=filter_size_d, strides = (2,2), input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256,  kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = g(noise)\n",
    "    d.trainable = False\n",
    "    #d_label.trainable = False\n",
    "    valid = d(img)\n",
    "    \n",
    "    \n",
    "    return Model(noise, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(epoch, gen):\n",
    "        count = 5\n",
    "        noise = np.random.uniform(-1, 1, size=(count, latent_dim))\n",
    "        gen_imgs = gen.predict(noise)\n",
    "\n",
    "        gen_imgs = 127.5 * gen_imgs + 127.5\n",
    "        \n",
    "        if gen_imgs.shape[3] == 1:\n",
    "            gen_imgs = gen_imgs[:,:,:,0]\n",
    "        \n",
    "        for i in range(count):\n",
    "            cv2.imwrite(os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, i), gen_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(indices, data, batch_size):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    for i in range(batch_size):\n",
    "        if color_mode == 'grayscale':\n",
    "            temp_img = cv2.imread(data[indices[i]], 0)\n",
    "            X_train[i,:,:,0] = temp_img\n",
    "        else:\n",
    "            temp_img = cv2.imread(data[indices[i]])\n",
    "            X_train[i] = temp_img\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_classes(batch_size, data):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size)\n",
    "    choice_arr = np.random.randint(0, len(data), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        rand_number = np.random.randint(0, len(data[choice_arr[i]]))\n",
    "        temp_img = cv2.imread(data[choice_arr[i]][rand_number])\n",
    "        \n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]\n",
    "    \n",
    "\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_one_class(batch_size, data, class_target):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size) + class_target\n",
    "    '''choice_arr = np.random.randint(0, len(data[class_target]), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(data[class_target][choice_arr[i]])\n",
    "\n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]'''\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(os.getcwd() + '/new256_images/abstraktnyy-ekspressionizm/303.png')\n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = 0\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], img_channels),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, :,]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    styles_folder = os.listdir(path=os.getcwd() + \"\\\\new256_images\\\\\")\n",
    "    num_styles = len(styles_folder)\n",
    "    data = []\n",
    "    for i in range(num_styles):\n",
    "        data.append(glob.glob(os.getcwd() + '\\\\new256_images\\\\' + styles_folder[i] + '\\\\*'))\n",
    "    return data, num_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_another(epochs = 100, BATCH_SIZE = 4):\n",
    "\n",
    "    data, num_styles = get_data()\n",
    "    \n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    discriminator.compile(loss=losses[0], optimizer=d_optim)\n",
    "    #d_label.compile(loss=losses[1], optimizer=d_optim)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    dcgan = generator_containing_discriminator(generator, discriminator)\n",
    "    \n",
    "    \n",
    "    dcgan.compile(loss=losses[0], optimizer=g_optim)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    #d_label.trainable = True\n",
    "    \n",
    "    \n",
    "    '''(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))'''\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for index in range(int(15000/BATCH_SIZE)):\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "                \n",
    "            #real_images, real_labels = get_images_classes(batch_size=BATCH_SIZE, data = data)\n",
    "            \n",
    "            label = index % num_styles\n",
    "            \n",
    "            real_images, real_labels = get_images_one_class(BATCH_SIZE, data, label)\n",
    "            \n",
    "            real_images += np.random.normal(size = img_shape, scale= 0.1)\n",
    "            \n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            if index % 2 == 0:\n",
    "                X = real_images\n",
    "                real_labels = real_labels - 0.1 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + label, num_styles)\n",
    "                y = 0.8 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                \n",
    "                d_loss = []\n",
    "                d_loss.append(discriminator.train_on_batch(X, y))\n",
    "                #discriminator.trainable = False\n",
    "                #d_loss.append(d_label.train_on_batch(X, y_classif))\n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss[0]))\n",
    "                \n",
    "                X = generated_images\n",
    "                y = np.random.rand(BATCH_SIZE) * 0.2\n",
    "                d_loss = discriminator.train_on_batch(X, y)\n",
    "                \n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss))\n",
    "            else:\n",
    "                X = generated_images\n",
    "                y = np.random.rand(BATCH_SIZE) * 0.2\n",
    "                d_loss = discriminator.train_on_batch(X, y)\n",
    "                \n",
    "                X = real_images\n",
    "                real_labels = real_labels - 0.1 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + label, num_styles)\n",
    "                y = 0.8 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                d_loss = (discriminator.train_on_batch(X, y))\n",
    "                \n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss))\n",
    "            \n",
    "            \n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "            \n",
    "            discriminator.trainable = False\n",
    "            #d_label.trainable = False\n",
    "            \n",
    "            y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + 0.5, num_styles)\n",
    "            y = np.random.rand(BATCH_SIZE) * 0.3\n",
    "            \n",
    "            g_loss = dcgan.train_on_batch(noise, y)\n",
    "            \n",
    "            #d_label.trainable = True\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            print(\"epoch %d batch %d g_loss : %f\" % (epoch, index, g_loss))\n",
    "            \n",
    "            if index % 50 == 0:\n",
    "                        image = combine_images(generated_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, index), image)\n",
    "                        image = combine_images(real_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d_data.png' % (epoch, index), image)\n",
    "                        \n",
    "        if epoch % 5 == 0:\n",
    "            \n",
    "            \n",
    "            date_today = date.today()\n",
    "            \n",
    "            \n",
    "            \n",
    "            month, day = date_today.month, date_today.day\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            d_json = discriminator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d dis_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            '''# Генерируем описание модели в формате json\n",
    "            d_l_json = d_label.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d dis_label_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_l_json)\n",
    "            json_file.close()'''\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            gen_json = generator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d gen_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(gen_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            discriminator.save_weights(os.getcwd() + '%d.%d dis_weights.h5' % (day, month))\n",
    "            #d_label.save_weights(os.getcwd() + '%d.%d dis_label_weights.h5' % (day, month))\n",
    "            generator.save_weights(os.getcwd() + '%d.%d gen_weights.h5' % (day, month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "img_channels = 3\n",
    "img_shape = (img_rows, img_cols, img_channels)\n",
    "latent_dim = 100\n",
    "filter_size_g = (5,5)\n",
    "filter_size_d = (5,5)\n",
    "d_strides = (2,2)\n",
    "\n",
    "color_mode = 'rgb'\n",
    "\n",
    "losses = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "\n",
    "\n",
    "#g_optim = SGD(lr = 0.001, momentum=0.9, nesterov=True)\n",
    "#d_optim = SGD(lr = 0.00025, momentum=0.9, nesterov=True)\n",
    "g_optim = Adam(0.0002, beta_2 = 0.5)\n",
    "d_optim = Adam(0.0002, beta_2 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 8, 8, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 16, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 64, 64, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 128, 128, 16)      12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 256, 256, 8)       3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256, 256, 8)       32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 256, 256, 3)       603       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 15,926,963\n",
      "Trainable params: 15,891,139\n",
      "Non-trainable params: 35,824\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,430,657\n",
      "Trainable params: 17,426,817\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "epoch 0 batch 0 d_loss : 0.961137\n",
      "epoch 0 batch 0 d_loss : 3.924104\n",
      "epoch 0 batch 0 g_loss : 1.877584\n",
      "epoch 0 batch 1 d_loss : 1.460673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 1 g_loss : 1.303733\n",
      "epoch 0 batch 2 d_loss : 1.363647\n",
      "epoch 0 batch 2 d_loss : 1.342477\n",
      "epoch 0 batch 2 g_loss : 2.127913\n",
      "epoch 0 batch 3 d_loss : 8.636152\n",
      "epoch 0 batch 3 g_loss : 2.621328\n",
      "epoch 0 batch 4 d_loss : 3.433769\n",
      "epoch 0 batch 4 d_loss : 1.583737\n",
      "epoch 0 batch 4 g_loss : 2.469853\n",
      "epoch 0 batch 5 d_loss : 1.435085\n",
      "epoch 0 batch 5 g_loss : 1.356680\n",
      "epoch 0 batch 6 d_loss : 1.308934\n",
      "epoch 0 batch 6 d_loss : 0.449827\n",
      "epoch 0 batch 6 g_loss : 1.434771\n",
      "epoch 0 batch 7 d_loss : 1.746174\n",
      "epoch 0 batch 7 g_loss : 0.820588\n",
      "epoch 0 batch 8 d_loss : 1.586899\n",
      "epoch 0 batch 8 d_loss : 1.067900\n",
      "epoch 0 batch 8 g_loss : 1.423277\n",
      "epoch 0 batch 9 d_loss : 1.747671\n",
      "epoch 0 batch 9 g_loss : 1.841674\n",
      "epoch 0 batch 10 d_loss : 1.472420\n",
      "epoch 0 batch 10 d_loss : 0.815985\n",
      "epoch 0 batch 10 g_loss : 0.964755\n",
      "epoch 0 batch 11 d_loss : 1.787125\n",
      "epoch 0 batch 11 g_loss : 1.021450\n",
      "epoch 0 batch 12 d_loss : 1.568441\n",
      "epoch 0 batch 12 d_loss : 4.103482\n",
      "epoch 0 batch 12 g_loss : 2.941073\n",
      "epoch 0 batch 13 d_loss : 1.625218\n",
      "epoch 0 batch 13 g_loss : 1.230614\n",
      "epoch 0 batch 14 d_loss : 1.523830\n",
      "epoch 0 batch 14 d_loss : 1.512483\n",
      "epoch 0 batch 14 g_loss : 2.218570\n",
      "epoch 0 batch 15 d_loss : 1.248202\n",
      "epoch 0 batch 15 g_loss : 2.498875\n",
      "epoch 0 batch 16 d_loss : 1.808729\n",
      "epoch 0 batch 16 d_loss : 1.912598\n",
      "epoch 0 batch 16 g_loss : 2.413055\n",
      "epoch 0 batch 17 d_loss : 2.031238\n",
      "epoch 0 batch 17 g_loss : 2.015098\n",
      "epoch 0 batch 18 d_loss : 1.475978\n",
      "epoch 0 batch 18 d_loss : 1.576727\n",
      "epoch 0 batch 18 g_loss : 2.716818\n",
      "epoch 0 batch 19 d_loss : 1.816930\n",
      "epoch 0 batch 19 g_loss : 1.947469\n",
      "epoch 0 batch 20 d_loss : 1.636738\n",
      "epoch 0 batch 20 d_loss : 1.814939\n",
      "epoch 0 batch 20 g_loss : 2.640201\n",
      "epoch 0 batch 21 d_loss : 0.481903\n",
      "epoch 0 batch 21 g_loss : 1.677800\n",
      "epoch 0 batch 22 d_loss : 0.522302\n",
      "epoch 0 batch 22 d_loss : 1.660025\n",
      "epoch 0 batch 22 g_loss : 1.747076\n",
      "epoch 0 batch 23 d_loss : 0.644360\n",
      "epoch 0 batch 23 g_loss : 2.371546\n",
      "epoch 0 batch 24 d_loss : 0.474363\n",
      "epoch 0 batch 24 d_loss : 1.637729\n",
      "epoch 0 batch 24 g_loss : 2.428264\n",
      "epoch 0 batch 25 d_loss : 5.161860\n",
      "epoch 0 batch 25 g_loss : 1.827410\n",
      "epoch 0 batch 26 d_loss : 2.775272\n",
      "epoch 0 batch 26 d_loss : 0.634480\n",
      "epoch 0 batch 26 g_loss : 0.982578\n",
      "epoch 0 batch 27 d_loss : 0.894986\n",
      "epoch 0 batch 27 g_loss : 0.676327\n",
      "epoch 0 batch 28 d_loss : 1.589182\n",
      "epoch 0 batch 28 d_loss : 1.817317\n",
      "epoch 0 batch 28 g_loss : 0.941190\n",
      "epoch 0 batch 29 d_loss : 1.469616\n",
      "epoch 0 batch 29 g_loss : 0.736862\n",
      "epoch 0 batch 30 d_loss : 1.523196\n",
      "epoch 0 batch 30 d_loss : 0.745583\n",
      "epoch 0 batch 30 g_loss : 0.926411\n",
      "epoch 0 batch 31 d_loss : 1.709110\n",
      "epoch 0 batch 31 g_loss : 0.887532\n",
      "epoch 0 batch 32 d_loss : 1.723930\n",
      "epoch 0 batch 32 d_loss : 0.520709\n",
      "epoch 0 batch 32 g_loss : 0.824312\n",
      "epoch 0 batch 33 d_loss : 1.378092\n",
      "epoch 0 batch 33 g_loss : 0.626703\n",
      "epoch 0 batch 34 d_loss : 1.215982\n",
      "epoch 0 batch 34 d_loss : 1.138736\n",
      "epoch 0 batch 34 g_loss : 0.814856\n",
      "epoch 0 batch 35 d_loss : 1.588016\n",
      "epoch 0 batch 35 g_loss : 0.546057\n",
      "epoch 0 batch 36 d_loss : 1.902169\n",
      "epoch 0 batch 36 d_loss : 0.610813\n",
      "epoch 0 batch 36 g_loss : 0.897143\n",
      "epoch 0 batch 37 d_loss : 1.885440\n",
      "epoch 0 batch 37 g_loss : 0.891242\n",
      "epoch 0 batch 38 d_loss : 1.710390\n",
      "epoch 0 batch 38 d_loss : 0.829793\n",
      "epoch 0 batch 38 g_loss : 1.018511\n",
      "epoch 0 batch 39 d_loss : 1.265232\n",
      "epoch 0 batch 39 g_loss : 1.367473\n",
      "epoch 0 batch 40 d_loss : 1.717479\n",
      "epoch 0 batch 40 d_loss : 0.995834\n",
      "epoch 0 batch 40 g_loss : 1.005643\n",
      "epoch 0 batch 41 d_loss : 1.791347\n",
      "epoch 0 batch 41 g_loss : 0.594788\n",
      "epoch 0 batch 42 d_loss : 1.588500\n",
      "epoch 0 batch 42 d_loss : 1.263971\n",
      "epoch 0 batch 42 g_loss : 0.587219\n",
      "epoch 0 batch 43 d_loss : 1.533421\n",
      "epoch 0 batch 43 g_loss : 0.764748\n",
      "epoch 0 batch 44 d_loss : 1.149875\n",
      "epoch 0 batch 44 d_loss : 1.018674\n",
      "epoch 0 batch 44 g_loss : 0.892117\n",
      "epoch 0 batch 45 d_loss : 0.977338\n",
      "epoch 0 batch 45 g_loss : 1.284520\n",
      "epoch 0 batch 46 d_loss : 0.863377\n",
      "epoch 0 batch 46 d_loss : 0.509114\n",
      "epoch 0 batch 46 g_loss : 1.196022\n",
      "epoch 0 batch 47 d_loss : 1.537323\n",
      "epoch 0 batch 47 g_loss : 1.669602\n",
      "epoch 0 batch 48 d_loss : 1.275409\n",
      "epoch 0 batch 48 d_loss : 0.466442\n",
      "epoch 0 batch 48 g_loss : 1.488777\n",
      "epoch 0 batch 49 d_loss : 0.437089\n",
      "epoch 0 batch 49 g_loss : 0.741347\n",
      "epoch 0 batch 50 d_loss : 0.603202\n",
      "epoch 0 batch 50 d_loss : 0.473517\n",
      "epoch 0 batch 50 g_loss : 0.599155\n",
      "epoch 0 batch 51 d_loss : 1.079225\n",
      "epoch 0 batch 51 g_loss : 1.122571\n",
      "epoch 0 batch 52 d_loss : 1.075329\n",
      "epoch 0 batch 52 d_loss : 1.923930\n",
      "epoch 0 batch 52 g_loss : 1.389479\n",
      "epoch 0 batch 53 d_loss : 1.188837\n",
      "epoch 0 batch 53 g_loss : 0.776248\n",
      "epoch 0 batch 54 d_loss : 1.034219\n",
      "epoch 0 batch 54 d_loss : 0.543931\n",
      "epoch 0 batch 54 g_loss : 1.090335\n",
      "epoch 0 batch 55 d_loss : 0.816412\n",
      "epoch 0 batch 55 g_loss : 1.561528\n",
      "epoch 0 batch 56 d_loss : 0.433548\n",
      "epoch 0 batch 56 d_loss : 0.967248\n",
      "epoch 0 batch 56 g_loss : 2.114457\n",
      "epoch 0 batch 57 d_loss : 1.353320\n",
      "epoch 0 batch 57 g_loss : 1.885399\n",
      "epoch 0 batch 58 d_loss : 1.119628\n",
      "epoch 0 batch 58 d_loss : 1.168615\n",
      "epoch 0 batch 58 g_loss : 1.356114\n",
      "epoch 0 batch 59 d_loss : 0.431452\n",
      "epoch 0 batch 59 g_loss : 1.254539\n",
      "epoch 0 batch 60 d_loss : 0.358304\n",
      "epoch 0 batch 60 d_loss : 0.636292\n",
      "epoch 0 batch 60 g_loss : 0.893777\n",
      "epoch 0 batch 61 d_loss : 0.663241\n",
      "epoch 0 batch 61 g_loss : 0.918946\n",
      "epoch 0 batch 62 d_loss : 1.011997\n",
      "epoch 0 batch 62 d_loss : 0.565250\n",
      "epoch 0 batch 62 g_loss : 0.609781\n",
      "epoch 0 batch 63 d_loss : 1.214057\n",
      "epoch 0 batch 63 g_loss : 0.795774\n",
      "epoch 0 batch 64 d_loss : 1.079829\n",
      "epoch 0 batch 64 d_loss : 0.413698\n",
      "epoch 0 batch 64 g_loss : 0.587550\n",
      "epoch 0 batch 65 d_loss : 0.904334\n",
      "epoch 0 batch 65 g_loss : 0.975038\n",
      "epoch 0 batch 66 d_loss : 0.865777\n",
      "epoch 0 batch 66 d_loss : 0.618926\n",
      "epoch 0 batch 66 g_loss : 0.971483\n",
      "epoch 0 batch 67 d_loss : 0.560402\n",
      "epoch 0 batch 67 g_loss : 1.334026\n",
      "epoch 0 batch 68 d_loss : 0.485705\n",
      "epoch 0 batch 68 d_loss : 0.790830\n",
      "epoch 0 batch 68 g_loss : 0.939143\n",
      "epoch 0 batch 69 d_loss : 0.333345\n",
      "epoch 0 batch 69 g_loss : 0.962217\n",
      "epoch 0 batch 70 d_loss : 0.411768\n",
      "epoch 0 batch 70 d_loss : 0.510111\n",
      "epoch 0 batch 70 g_loss : 0.655695\n",
      "epoch 0 batch 71 d_loss : 0.395039\n",
      "epoch 0 batch 71 g_loss : 0.488641\n",
      "epoch 0 batch 72 d_loss : 0.367361\n",
      "epoch 0 batch 72 d_loss : 0.435993\n",
      "epoch 0 batch 72 g_loss : 0.477770\n",
      "epoch 0 batch 73 d_loss : 0.313838\n",
      "epoch 0 batch 73 g_loss : 0.465160\n",
      "epoch 0 batch 74 d_loss : 0.425009\n",
      "epoch 0 batch 74 d_loss : 0.501558\n",
      "epoch 0 batch 74 g_loss : 0.543323\n",
      "epoch 0 batch 75 d_loss : 0.347426\n",
      "epoch 0 batch 75 g_loss : 0.463627\n",
      "epoch 0 batch 76 d_loss : 0.296994\n",
      "epoch 0 batch 76 d_loss : 0.329067\n",
      "epoch 0 batch 76 g_loss : 0.526535\n",
      "epoch 0 batch 77 d_loss : 0.383806\n",
      "epoch 0 batch 77 g_loss : 0.993514\n",
      "epoch 0 batch 78 d_loss : 0.365896\n",
      "epoch 0 batch 78 d_loss : 0.533831\n",
      "epoch 0 batch 78 g_loss : 1.011236\n",
      "epoch 0 batch 79 d_loss : 0.351691\n",
      "epoch 0 batch 79 g_loss : 0.878689\n",
      "epoch 0 batch 80 d_loss : 0.373756\n",
      "epoch 0 batch 80 d_loss : 0.303730\n",
      "epoch 0 batch 80 g_loss : 0.630498\n",
      "epoch 0 batch 81 d_loss : 0.426863\n",
      "epoch 0 batch 81 g_loss : 0.381328\n",
      "epoch 0 batch 82 d_loss : 0.390624\n",
      "epoch 0 batch 82 d_loss : 0.468914\n",
      "epoch 0 batch 82 g_loss : 0.452917\n",
      "epoch 0 batch 83 d_loss : 0.319465\n",
      "epoch 0 batch 83 g_loss : 0.529780\n",
      "epoch 0 batch 84 d_loss : 0.342632\n",
      "epoch 0 batch 84 d_loss : 0.358173\n",
      "epoch 0 batch 84 g_loss : 0.545284\n",
      "epoch 0 batch 85 d_loss : 0.529416\n",
      "epoch 0 batch 85 g_loss : 0.485164\n",
      "epoch 0 batch 86 d_loss : 0.402096\n",
      "epoch 0 batch 86 d_loss : 0.369292\n",
      "epoch 0 batch 86 g_loss : 0.739882\n",
      "epoch 0 batch 87 d_loss : 0.348551\n",
      "epoch 0 batch 87 g_loss : 0.567835\n",
      "epoch 0 batch 88 d_loss : 0.435977\n",
      "epoch 0 batch 88 d_loss : 0.434809\n",
      "epoch 0 batch 88 g_loss : 0.456069\n",
      "epoch 0 batch 89 d_loss : 0.367069\n",
      "epoch 0 batch 89 g_loss : 0.503591\n",
      "epoch 0 batch 90 d_loss : 0.530626\n",
      "epoch 0 batch 90 d_loss : 0.410814\n",
      "epoch 0 batch 90 g_loss : 0.468999\n",
      "epoch 0 batch 91 d_loss : 0.346353\n",
      "epoch 0 batch 91 g_loss : 0.544601\n",
      "epoch 0 batch 92 d_loss : 0.320525\n",
      "epoch 0 batch 92 d_loss : 0.372491\n",
      "epoch 0 batch 92 g_loss : 0.411482\n",
      "epoch 0 batch 93 d_loss : 0.425787\n",
      "epoch 0 batch 93 g_loss : 0.556102\n",
      "epoch 0 batch 94 d_loss : 0.419800\n",
      "epoch 0 batch 94 d_loss : 0.372757\n",
      "epoch 0 batch 94 g_loss : 0.419836\n",
      "epoch 0 batch 95 d_loss : 0.287943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 95 g_loss : 0.562354\n",
      "epoch 0 batch 96 d_loss : 0.325979\n",
      "epoch 0 batch 96 d_loss : 0.483537\n",
      "epoch 0 batch 96 g_loss : 0.567107\n",
      "epoch 0 batch 97 d_loss : 0.480738\n",
      "epoch 0 batch 97 g_loss : 0.446221\n",
      "epoch 0 batch 98 d_loss : 0.466531\n",
      "epoch 0 batch 98 d_loss : 0.383300\n",
      "epoch 0 batch 98 g_loss : 0.439104\n",
      "epoch 0 batch 99 d_loss : 0.438670\n",
      "epoch 0 batch 99 g_loss : 0.361872\n",
      "epoch 0 batch 100 d_loss : 0.321592\n",
      "epoch 0 batch 100 d_loss : 0.378003\n",
      "epoch 0 batch 100 g_loss : 0.381661\n",
      "epoch 0 batch 101 d_loss : 0.584357\n",
      "epoch 0 batch 101 g_loss : 0.470357\n",
      "epoch 0 batch 102 d_loss : 0.539615\n",
      "epoch 0 batch 102 d_loss : 0.442601\n",
      "epoch 0 batch 102 g_loss : 0.531335\n",
      "epoch 0 batch 103 d_loss : 0.344257\n",
      "epoch 0 batch 103 g_loss : 0.582429\n",
      "epoch 0 batch 104 d_loss : 0.351591\n",
      "epoch 0 batch 104 d_loss : 0.422082\n",
      "epoch 0 batch 104 g_loss : 0.375276\n",
      "epoch 0 batch 105 d_loss : 0.668140\n",
      "epoch 0 batch 105 g_loss : 0.463188\n",
      "epoch 0 batch 106 d_loss : 0.422796\n",
      "epoch 0 batch 106 d_loss : 0.456677\n",
      "epoch 0 batch 106 g_loss : 0.388420\n",
      "epoch 0 batch 107 d_loss : 0.479373\n",
      "epoch 0 batch 107 g_loss : 0.554018\n",
      "epoch 0 batch 108 d_loss : 0.420219\n",
      "epoch 0 batch 108 d_loss : 0.409799\n",
      "epoch 0 batch 108 g_loss : 0.518515\n",
      "epoch 0 batch 109 d_loss : 0.352822\n",
      "epoch 0 batch 109 g_loss : 0.615773\n",
      "epoch 0 batch 110 d_loss : 0.333042\n",
      "epoch 0 batch 110 d_loss : 0.395839\n",
      "epoch 0 batch 110 g_loss : 0.808712\n",
      "epoch 0 batch 111 d_loss : 0.596326\n",
      "epoch 0 batch 111 g_loss : 0.445260\n",
      "epoch 0 batch 112 d_loss : 0.493919\n",
      "epoch 0 batch 112 d_loss : 0.317473\n",
      "epoch 0 batch 112 g_loss : 0.498648\n",
      "epoch 0 batch 113 d_loss : 0.347228\n",
      "epoch 0 batch 113 g_loss : 0.454119\n",
      "epoch 0 batch 114 d_loss : 0.359391\n",
      "epoch 0 batch 114 d_loss : 0.532414\n",
      "epoch 0 batch 114 g_loss : 0.504331\n",
      "epoch 0 batch 115 d_loss : 0.343834\n",
      "epoch 0 batch 115 g_loss : 0.479948\n",
      "epoch 0 batch 116 d_loss : 0.455326\n",
      "epoch 0 batch 116 d_loss : 0.324414\n",
      "epoch 0 batch 116 g_loss : 0.607855\n",
      "epoch 0 batch 117 d_loss : 0.373843\n",
      "epoch 0 batch 117 g_loss : 0.617219\n",
      "epoch 0 batch 118 d_loss : 0.321326\n",
      "epoch 0 batch 118 d_loss : 0.524996\n",
      "epoch 0 batch 118 g_loss : 0.688040\n",
      "epoch 0 batch 119 d_loss : 0.366712\n",
      "epoch 0 batch 119 g_loss : 0.855893\n",
      "epoch 0 batch 120 d_loss : 0.411727\n",
      "epoch 0 batch 120 d_loss : 0.305847\n",
      "epoch 0 batch 120 g_loss : 0.620665\n",
      "epoch 0 batch 121 d_loss : 0.276699\n",
      "epoch 0 batch 121 g_loss : 0.461074\n",
      "epoch 0 batch 122 d_loss : 0.361530\n",
      "epoch 0 batch 122 d_loss : 0.431159\n",
      "epoch 0 batch 122 g_loss : 0.493575\n",
      "epoch 0 batch 123 d_loss : 0.393295\n",
      "epoch 0 batch 123 g_loss : 0.519596\n",
      "epoch 0 batch 124 d_loss : 0.365006\n",
      "epoch 0 batch 124 d_loss : 0.412089\n",
      "epoch 0 batch 124 g_loss : 0.607295\n",
      "epoch 0 batch 125 d_loss : 0.312881\n",
      "epoch 0 batch 125 g_loss : 0.568825\n",
      "epoch 0 batch 126 d_loss : 0.290641\n",
      "epoch 0 batch 126 d_loss : 0.376524\n",
      "epoch 0 batch 126 g_loss : 0.619237\n",
      "epoch 0 batch 127 d_loss : 0.308162\n",
      "epoch 0 batch 127 g_loss : 0.729511\n",
      "epoch 0 batch 128 d_loss : 0.301119\n",
      "epoch 0 batch 128 d_loss : 0.408978\n",
      "epoch 0 batch 128 g_loss : 0.671638\n",
      "epoch 0 batch 129 d_loss : 0.320386\n",
      "epoch 0 batch 129 g_loss : 0.524107\n",
      "epoch 0 batch 130 d_loss : 0.416031\n",
      "epoch 0 batch 130 d_loss : 0.391484\n",
      "epoch 0 batch 130 g_loss : 0.653805\n",
      "epoch 0 batch 131 d_loss : 0.368837\n",
      "epoch 0 batch 131 g_loss : 0.461113\n",
      "epoch 0 batch 132 d_loss : 0.297239\n",
      "epoch 0 batch 132 d_loss : 0.379416\n",
      "epoch 0 batch 132 g_loss : 0.562893\n",
      "epoch 0 batch 133 d_loss : 0.375006\n",
      "epoch 0 batch 133 g_loss : 0.444829\n",
      "epoch 0 batch 134 d_loss : 0.307936\n",
      "epoch 0 batch 134 d_loss : 0.387009\n",
      "epoch 0 batch 134 g_loss : 0.491486\n",
      "epoch 0 batch 135 d_loss : 0.362018\n",
      "epoch 0 batch 135 g_loss : 0.542516\n",
      "epoch 0 batch 136 d_loss : 0.435081\n",
      "epoch 0 batch 136 d_loss : 0.361301\n",
      "epoch 0 batch 136 g_loss : 0.684294\n",
      "epoch 0 batch 137 d_loss : 0.358994\n",
      "epoch 0 batch 137 g_loss : 0.472131\n",
      "epoch 0 batch 138 d_loss : 0.375159\n",
      "epoch 0 batch 138 d_loss : 0.619636\n",
      "epoch 0 batch 138 g_loss : 0.674147\n",
      "epoch 0 batch 139 d_loss : 0.343853\n",
      "epoch 0 batch 139 g_loss : 0.569084\n",
      "epoch 0 batch 140 d_loss : 0.367917\n",
      "epoch 0 batch 140 d_loss : 0.340316\n",
      "epoch 0 batch 140 g_loss : 0.469986\n",
      "epoch 0 batch 141 d_loss : 0.344217\n",
      "epoch 0 batch 141 g_loss : 0.489433\n",
      "epoch 0 batch 142 d_loss : 0.401765\n",
      "epoch 0 batch 142 d_loss : 0.344958\n",
      "epoch 0 batch 142 g_loss : 0.475978\n",
      "epoch 0 batch 143 d_loss : 0.336426\n",
      "epoch 0 batch 143 g_loss : 0.484515\n",
      "epoch 0 batch 144 d_loss : 0.319704\n",
      "epoch 0 batch 144 d_loss : 0.382991\n",
      "epoch 0 batch 144 g_loss : 0.434786\n",
      "epoch 0 batch 145 d_loss : 0.313837\n",
      "epoch 0 batch 145 g_loss : 0.537888\n",
      "epoch 0 batch 146 d_loss : 0.327693\n",
      "epoch 0 batch 146 d_loss : 0.345481\n",
      "epoch 0 batch 146 g_loss : 0.481519\n",
      "epoch 0 batch 147 d_loss : 0.365975\n",
      "epoch 0 batch 147 g_loss : 0.659535\n",
      "epoch 0 batch 148 d_loss : 0.349156\n",
      "epoch 0 batch 148 d_loss : 0.360046\n",
      "epoch 0 batch 148 g_loss : 0.524030\n",
      "epoch 0 batch 149 d_loss : 0.420587\n",
      "epoch 0 batch 149 g_loss : 0.421979\n",
      "epoch 0 batch 150 d_loss : 0.351235\n",
      "epoch 0 batch 150 d_loss : 0.347076\n",
      "epoch 0 batch 150 g_loss : 0.518568\n",
      "epoch 0 batch 151 d_loss : 0.460652\n",
      "epoch 0 batch 151 g_loss : 0.428285\n",
      "epoch 0 batch 152 d_loss : 0.392852\n",
      "epoch 0 batch 152 d_loss : 0.500926\n",
      "epoch 0 batch 152 g_loss : 0.460196\n",
      "epoch 0 batch 153 d_loss : 0.333339\n",
      "epoch 0 batch 153 g_loss : 0.451539\n",
      "epoch 0 batch 154 d_loss : 0.356181\n",
      "epoch 0 batch 154 d_loss : 0.334858\n",
      "epoch 0 batch 154 g_loss : 0.461123\n",
      "epoch 0 batch 155 d_loss : 0.538176\n",
      "epoch 0 batch 155 g_loss : 0.609560\n",
      "epoch 0 batch 156 d_loss : 0.292057\n",
      "epoch 0 batch 156 d_loss : 0.352776\n",
      "epoch 0 batch 156 g_loss : 0.595394\n",
      "epoch 0 batch 157 d_loss : 0.466269\n",
      "epoch 0 batch 157 g_loss : 0.652751\n",
      "epoch 0 batch 158 d_loss : 0.381884\n",
      "epoch 0 batch 158 d_loss : 0.435826\n",
      "epoch 0 batch 158 g_loss : 0.666929\n",
      "epoch 0 batch 159 d_loss : 0.370381\n",
      "epoch 0 batch 159 g_loss : 0.613327\n",
      "epoch 0 batch 160 d_loss : 0.367312\n",
      "epoch 0 batch 160 d_loss : 0.368174\n",
      "epoch 0 batch 160 g_loss : 0.473688\n",
      "epoch 0 batch 161 d_loss : 0.350475\n",
      "epoch 0 batch 161 g_loss : 0.417601\n",
      "epoch 0 batch 162 d_loss : 0.265008\n",
      "epoch 0 batch 162 d_loss : 0.424832\n",
      "epoch 0 batch 162 g_loss : 0.496318\n",
      "epoch 0 batch 163 d_loss : 0.309790\n",
      "epoch 0 batch 163 g_loss : 0.509348\n",
      "epoch 0 batch 164 d_loss : 0.315394\n",
      "epoch 0 batch 164 d_loss : 0.325124\n",
      "epoch 0 batch 164 g_loss : 0.327615\n",
      "epoch 0 batch 165 d_loss : 0.432804\n",
      "epoch 0 batch 165 g_loss : 0.519552\n",
      "epoch 0 batch 166 d_loss : 0.335250\n",
      "epoch 0 batch 166 d_loss : 0.347520\n",
      "epoch 0 batch 166 g_loss : 0.849600\n",
      "epoch 0 batch 167 d_loss : 0.376413\n",
      "epoch 0 batch 167 g_loss : 0.616106\n",
      "epoch 0 batch 168 d_loss : 0.327999\n",
      "epoch 0 batch 168 d_loss : 0.358861\n",
      "epoch 0 batch 168 g_loss : 0.631554\n",
      "epoch 0 batch 169 d_loss : 0.370721\n",
      "epoch 0 batch 169 g_loss : 0.448611\n",
      "epoch 0 batch 170 d_loss : 0.389296\n",
      "epoch 0 batch 170 d_loss : 0.348607\n",
      "epoch 0 batch 170 g_loss : 0.422840\n",
      "epoch 0 batch 171 d_loss : 0.297484\n",
      "epoch 0 batch 171 g_loss : 0.417755\n",
      "epoch 0 batch 172 d_loss : 0.306302\n",
      "epoch 0 batch 172 d_loss : 0.364616\n",
      "epoch 0 batch 172 g_loss : 0.474260\n",
      "epoch 0 batch 173 d_loss : 0.375238\n",
      "epoch 0 batch 173 g_loss : 0.473576\n",
      "epoch 0 batch 174 d_loss : 0.327886\n",
      "epoch 0 batch 174 d_loss : 0.335977\n",
      "epoch 0 batch 174 g_loss : 0.463408\n",
      "epoch 0 batch 175 d_loss : 0.360957\n",
      "epoch 0 batch 175 g_loss : 0.517689\n",
      "epoch 0 batch 176 d_loss : 0.364142\n",
      "epoch 0 batch 176 d_loss : 0.384683\n",
      "epoch 0 batch 176 g_loss : 0.429893\n",
      "epoch 0 batch 177 d_loss : 0.269675\n",
      "epoch 0 batch 177 g_loss : 0.448684\n",
      "epoch 0 batch 178 d_loss : 0.368585\n",
      "epoch 0 batch 178 d_loss : 0.362786\n",
      "epoch 0 batch 178 g_loss : 0.418850\n",
      "epoch 0 batch 179 d_loss : 0.396163\n",
      "epoch 0 batch 179 g_loss : 0.346446\n",
      "epoch 0 batch 180 d_loss : 0.400370\n",
      "epoch 0 batch 180 d_loss : 0.382334\n",
      "epoch 0 batch 180 g_loss : 0.462891\n",
      "epoch 0 batch 181 d_loss : 0.391041\n",
      "epoch 0 batch 181 g_loss : 0.522050\n",
      "epoch 0 batch 182 d_loss : 0.362086\n",
      "epoch 0 batch 182 d_loss : 0.267375\n",
      "epoch 0 batch 182 g_loss : 0.667552\n",
      "epoch 0 batch 183 d_loss : 0.350708\n",
      "epoch 0 batch 183 g_loss : 0.458345\n",
      "epoch 0 batch 184 d_loss : 0.388846\n",
      "epoch 0 batch 184 d_loss : 0.473784\n",
      "epoch 0 batch 184 g_loss : 0.554204\n",
      "epoch 0 batch 185 d_loss : 0.309141\n",
      "epoch 0 batch 185 g_loss : 0.553906\n",
      "epoch 0 batch 186 d_loss : 0.293444\n",
      "epoch 0 batch 186 d_loss : 0.424033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 186 g_loss : 0.474193\n",
      "epoch 0 batch 187 d_loss : 0.325893\n",
      "epoch 0 batch 187 g_loss : 0.491525\n",
      "epoch 0 batch 188 d_loss : 0.345306\n",
      "epoch 0 batch 188 d_loss : 0.371535\n",
      "epoch 0 batch 188 g_loss : 0.369648\n",
      "epoch 0 batch 189 d_loss : 0.353672\n",
      "epoch 0 batch 189 g_loss : 0.470407\n",
      "epoch 0 batch 190 d_loss : 0.305564\n",
      "epoch 0 batch 190 d_loss : 0.267376\n",
      "epoch 0 batch 190 g_loss : 0.607069\n",
      "epoch 0 batch 191 d_loss : 0.356192\n",
      "epoch 0 batch 191 g_loss : 0.388038\n",
      "epoch 0 batch 192 d_loss : 0.331002\n",
      "epoch 0 batch 192 d_loss : 0.350244\n",
      "epoch 0 batch 192 g_loss : 0.473267\n",
      "epoch 0 batch 193 d_loss : 0.399654\n",
      "epoch 0 batch 193 g_loss : 0.424764\n",
      "epoch 0 batch 194 d_loss : 0.334980\n",
      "epoch 0 batch 194 d_loss : 0.431021\n",
      "epoch 0 batch 194 g_loss : 0.450940\n",
      "epoch 0 batch 195 d_loss : 0.370476\n",
      "epoch 0 batch 195 g_loss : 0.524459\n",
      "epoch 0 batch 196 d_loss : 0.328024\n",
      "epoch 0 batch 196 d_loss : 0.399700\n",
      "epoch 0 batch 196 g_loss : 0.570272\n",
      "epoch 0 batch 197 d_loss : 0.327618\n",
      "epoch 0 batch 197 g_loss : 0.492147\n",
      "epoch 0 batch 198 d_loss : 0.314614\n",
      "epoch 0 batch 198 d_loss : 0.369517\n",
      "epoch 0 batch 198 g_loss : 0.635924\n",
      "epoch 0 batch 199 d_loss : 0.362113\n",
      "epoch 0 batch 199 g_loss : 0.549570\n",
      "epoch 0 batch 200 d_loss : 0.385909\n",
      "epoch 0 batch 200 d_loss : 0.331757\n",
      "epoch 0 batch 200 g_loss : 0.684955\n",
      "epoch 0 batch 201 d_loss : 0.330508\n",
      "epoch 0 batch 201 g_loss : 0.391544\n",
      "epoch 0 batch 202 d_loss : 0.320807\n",
      "epoch 0 batch 202 d_loss : 0.371978\n",
      "epoch 0 batch 202 g_loss : 0.444860\n",
      "epoch 0 batch 203 d_loss : 0.408963\n",
      "epoch 0 batch 203 g_loss : 0.346834\n",
      "epoch 0 batch 204 d_loss : 0.380430\n",
      "epoch 0 batch 204 d_loss : 0.364822\n",
      "epoch 0 batch 204 g_loss : 0.474882\n",
      "epoch 0 batch 205 d_loss : 0.326143\n",
      "epoch 0 batch 205 g_loss : 0.426804\n",
      "epoch 0 batch 206 d_loss : 0.286670\n",
      "epoch 0 batch 206 d_loss : 0.435760\n",
      "epoch 0 batch 206 g_loss : 0.598333\n",
      "epoch 0 batch 207 d_loss : 0.577694\n",
      "epoch 0 batch 207 g_loss : 0.466049\n",
      "epoch 0 batch 208 d_loss : 0.465821\n",
      "epoch 0 batch 208 d_loss : 0.370247\n",
      "epoch 0 batch 208 g_loss : 0.436738\n",
      "epoch 0 batch 209 d_loss : 0.307896\n",
      "epoch 0 batch 209 g_loss : 0.507159\n",
      "epoch 0 batch 210 d_loss : 0.295178\n",
      "epoch 0 batch 210 d_loss : 0.351425\n",
      "epoch 0 batch 210 g_loss : 0.420591\n",
      "epoch 0 batch 211 d_loss : 0.456668\n",
      "epoch 0 batch 211 g_loss : 0.413565\n",
      "epoch 0 batch 212 d_loss : 0.430580\n",
      "epoch 0 batch 212 d_loss : 0.412907\n",
      "epoch 0 batch 212 g_loss : 0.466354\n",
      "epoch 0 batch 213 d_loss : 0.346680\n",
      "epoch 0 batch 213 g_loss : 0.517568\n",
      "epoch 0 batch 214 d_loss : 0.318969\n",
      "epoch 0 batch 214 d_loss : 0.403644\n",
      "epoch 0 batch 214 g_loss : 0.423651\n",
      "epoch 0 batch 215 d_loss : 0.395102\n",
      "epoch 0 batch 215 g_loss : 0.377425\n",
      "epoch 0 batch 216 d_loss : 0.407278\n",
      "epoch 0 batch 216 d_loss : 0.262793\n",
      "epoch 0 batch 216 g_loss : 0.553664\n",
      "epoch 0 batch 217 d_loss : 0.391282\n",
      "epoch 0 batch 217 g_loss : 0.559133\n",
      "epoch 0 batch 218 d_loss : 0.342342\n",
      "epoch 0 batch 218 d_loss : 0.380429\n",
      "epoch 0 batch 218 g_loss : 0.656599\n",
      "epoch 0 batch 219 d_loss : 0.433053\n",
      "epoch 0 batch 219 g_loss : 0.560315\n",
      "epoch 0 batch 220 d_loss : 0.315384\n",
      "epoch 0 batch 220 d_loss : 0.380941\n",
      "epoch 0 batch 220 g_loss : 0.461362\n",
      "epoch 0 batch 221 d_loss : 0.471335\n",
      "epoch 0 batch 221 g_loss : 0.432992\n",
      "epoch 0 batch 222 d_loss : 0.436536\n",
      "epoch 0 batch 222 d_loss : 0.454613\n",
      "epoch 0 batch 222 g_loss : 0.496073\n",
      "epoch 0 batch 223 d_loss : 0.338999\n",
      "epoch 0 batch 223 g_loss : 0.450250\n",
      "epoch 0 batch 224 d_loss : 0.314953\n",
      "epoch 0 batch 224 d_loss : 0.378231\n",
      "epoch 0 batch 224 g_loss : 0.471857\n",
      "epoch 0 batch 225 d_loss : 0.302816\n",
      "epoch 0 batch 225 g_loss : 0.645439\n",
      "epoch 0 batch 226 d_loss : 0.272231\n",
      "epoch 0 batch 226 d_loss : 0.324608\n",
      "epoch 0 batch 226 g_loss : 0.735213\n",
      "epoch 0 batch 227 d_loss : 0.452334\n",
      "epoch 0 batch 227 g_loss : 0.652575\n",
      "epoch 0 batch 228 d_loss : 0.399953\n",
      "epoch 0 batch 228 d_loss : 0.471268\n",
      "epoch 0 batch 228 g_loss : 0.733985\n",
      "epoch 0 batch 229 d_loss : 0.323573\n",
      "epoch 0 batch 229 g_loss : 0.682671\n",
      "epoch 0 batch 230 d_loss : 0.277207\n",
      "epoch 0 batch 230 d_loss : 0.483745\n",
      "epoch 0 batch 230 g_loss : 0.551662\n",
      "epoch 0 batch 231 d_loss : 0.364762\n",
      "epoch 0 batch 231 g_loss : 0.389085\n",
      "epoch 0 batch 232 d_loss : 0.380385\n",
      "epoch 0 batch 232 d_loss : 0.293871\n",
      "epoch 0 batch 232 g_loss : 0.412310\n",
      "epoch 0 batch 233 d_loss : 0.427817\n",
      "epoch 0 batch 233 g_loss : 0.349740\n",
      "epoch 0 batch 234 d_loss : 0.401266\n",
      "epoch 0 batch 234 d_loss : 0.350714\n",
      "epoch 0 batch 234 g_loss : 0.384255\n",
      "epoch 0 batch 235 d_loss : 0.342462\n",
      "epoch 0 batch 235 g_loss : 0.401258\n",
      "epoch 0 batch 236 d_loss : 0.299563\n",
      "epoch 0 batch 236 d_loss : 0.368658\n",
      "epoch 0 batch 236 g_loss : 0.497313\n",
      "epoch 0 batch 237 d_loss : 0.394820\n",
      "epoch 0 batch 237 g_loss : 0.424418\n",
      "epoch 0 batch 238 d_loss : 0.378210\n",
      "epoch 0 batch 238 d_loss : 0.296198\n",
      "epoch 0 batch 238 g_loss : 0.395467\n",
      "epoch 0 batch 239 d_loss : 0.361394\n",
      "epoch 0 batch 239 g_loss : 0.601026\n",
      "epoch 0 batch 240 d_loss : 0.309047\n",
      "epoch 0 batch 240 d_loss : 0.373578\n",
      "epoch 0 batch 240 g_loss : 0.595558\n",
      "epoch 0 batch 241 d_loss : 0.348927\n",
      "epoch 0 batch 241 g_loss : 0.505176\n",
      "epoch 0 batch 242 d_loss : 0.295237\n",
      "epoch 0 batch 242 d_loss : 0.311637\n",
      "epoch 0 batch 242 g_loss : 0.460639\n",
      "epoch 0 batch 243 d_loss : 0.368601\n",
      "epoch 0 batch 243 g_loss : 0.411243\n",
      "epoch 0 batch 244 d_loss : 0.369673\n",
      "epoch 0 batch 244 d_loss : 0.339326\n",
      "epoch 0 batch 244 g_loss : 0.480466\n",
      "epoch 0 batch 245 d_loss : 0.334018\n",
      "epoch 0 batch 245 g_loss : 0.443745\n",
      "epoch 0 batch 246 d_loss : 0.412111\n",
      "epoch 0 batch 246 d_loss : 0.376305\n",
      "epoch 0 batch 246 g_loss : 0.411038\n",
      "epoch 0 batch 247 d_loss : 0.331684\n",
      "epoch 0 batch 247 g_loss : 0.448490\n",
      "epoch 0 batch 248 d_loss : 0.328853\n",
      "epoch 0 batch 248 d_loss : 0.414625\n",
      "epoch 0 batch 248 g_loss : 0.445767\n",
      "epoch 0 batch 249 d_loss : 0.270027\n",
      "epoch 0 batch 249 g_loss : 0.436042\n",
      "epoch 0 batch 250 d_loss : 0.335055\n",
      "epoch 0 batch 250 d_loss : 0.315732\n",
      "epoch 0 batch 250 g_loss : 0.557022\n",
      "epoch 0 batch 251 d_loss : 0.301234\n",
      "epoch 0 batch 251 g_loss : 0.527199\n",
      "epoch 0 batch 252 d_loss : 0.292058\n",
      "epoch 0 batch 252 d_loss : 0.389305\n",
      "epoch 0 batch 252 g_loss : 0.765675\n",
      "epoch 0 batch 253 d_loss : 0.402977\n",
      "epoch 0 batch 253 g_loss : 0.700804\n",
      "epoch 0 batch 254 d_loss : 0.409981\n",
      "epoch 0 batch 254 d_loss : 0.418020\n",
      "epoch 0 batch 254 g_loss : 0.435123\n",
      "epoch 0 batch 255 d_loss : 0.311198\n",
      "epoch 0 batch 255 g_loss : 0.512150\n",
      "epoch 0 batch 256 d_loss : 0.390987\n",
      "epoch 0 batch 256 d_loss : 0.376463\n",
      "epoch 0 batch 256 g_loss : 0.501053\n",
      "epoch 0 batch 257 d_loss : 0.362887\n",
      "epoch 0 batch 257 g_loss : 0.367999\n",
      "epoch 0 batch 258 d_loss : 0.325463\n",
      "epoch 0 batch 258 d_loss : 0.288893\n",
      "epoch 0 batch 258 g_loss : 0.490570\n",
      "epoch 0 batch 259 d_loss : 0.334848\n",
      "epoch 0 batch 259 g_loss : 0.505581\n",
      "epoch 0 batch 260 d_loss : 0.320919\n",
      "epoch 0 batch 260 d_loss : 0.377132\n",
      "epoch 0 batch 260 g_loss : 0.414759\n",
      "epoch 0 batch 261 d_loss : 0.366857\n",
      "epoch 0 batch 261 g_loss : 0.463830\n",
      "epoch 0 batch 262 d_loss : 0.279367\n",
      "epoch 0 batch 262 d_loss : 0.354030\n",
      "epoch 0 batch 262 g_loss : 0.448627\n",
      "epoch 0 batch 263 d_loss : 0.384560\n",
      "epoch 0 batch 263 g_loss : 0.518208\n",
      "epoch 0 batch 264 d_loss : 0.316252\n",
      "epoch 0 batch 264 d_loss : 0.357306\n",
      "epoch 0 batch 264 g_loss : 0.428483\n",
      "epoch 0 batch 265 d_loss : 0.301950\n",
      "epoch 0 batch 265 g_loss : 0.558160\n",
      "epoch 0 batch 266 d_loss : 0.368507\n",
      "epoch 0 batch 266 d_loss : 0.300975\n",
      "epoch 0 batch 266 g_loss : 0.364044\n",
      "epoch 0 batch 267 d_loss : 0.302246\n",
      "epoch 0 batch 267 g_loss : 0.428789\n",
      "epoch 0 batch 268 d_loss : 0.307065\n",
      "epoch 0 batch 268 d_loss : 0.345918\n",
      "epoch 0 batch 268 g_loss : 0.340388\n",
      "epoch 0 batch 269 d_loss : 0.335673\n",
      "epoch 0 batch 269 g_loss : 0.420834\n",
      "epoch 0 batch 270 d_loss : 0.368144\n",
      "epoch 0 batch 270 d_loss : 0.390095\n",
      "epoch 0 batch 270 g_loss : 0.426289\n",
      "epoch 0 batch 271 d_loss : 0.349078\n",
      "epoch 0 batch 271 g_loss : 0.426091\n",
      "epoch 0 batch 272 d_loss : 0.300483\n",
      "epoch 0 batch 272 d_loss : 0.300532\n",
      "epoch 0 batch 272 g_loss : 0.553008\n",
      "epoch 0 batch 273 d_loss : 0.298884\n",
      "epoch 0 batch 273 g_loss : 0.407556\n",
      "epoch 0 batch 274 d_loss : 0.341286\n",
      "epoch 0 batch 274 d_loss : 0.367135\n",
      "epoch 0 batch 274 g_loss : 0.441670\n",
      "epoch 0 batch 275 d_loss : 0.339339\n",
      "epoch 0 batch 275 g_loss : 0.357490\n",
      "epoch 0 batch 276 d_loss : 0.312393\n",
      "epoch 0 batch 276 d_loss : 0.386547\n",
      "epoch 0 batch 276 g_loss : 0.435379\n",
      "epoch 0 batch 277 d_loss : 0.359123\n",
      "epoch 0 batch 277 g_loss : 0.504765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 278 d_loss : 0.382660\n",
      "epoch 0 batch 278 d_loss : 0.258614\n",
      "epoch 0 batch 278 g_loss : 0.424284\n",
      "epoch 0 batch 279 d_loss : 0.369728\n",
      "epoch 0 batch 279 g_loss : 0.600507\n",
      "epoch 0 batch 280 d_loss : 0.346475\n",
      "epoch 0 batch 280 d_loss : 0.313315\n",
      "epoch 0 batch 280 g_loss : 0.536906\n",
      "epoch 0 batch 281 d_loss : 0.465716\n",
      "epoch 0 batch 281 g_loss : 0.432328\n",
      "epoch 0 batch 282 d_loss : 0.356463\n",
      "epoch 0 batch 282 d_loss : 0.287438\n",
      "epoch 0 batch 282 g_loss : 0.517873\n",
      "epoch 0 batch 283 d_loss : 0.261049\n",
      "epoch 0 batch 283 g_loss : 0.437416\n",
      "epoch 0 batch 284 d_loss : 0.350417\n",
      "epoch 0 batch 284 d_loss : 0.271682\n",
      "epoch 0 batch 284 g_loss : 0.557264\n",
      "epoch 0 batch 285 d_loss : 0.323943\n",
      "epoch 0 batch 285 g_loss : 0.546530\n",
      "epoch 0 batch 286 d_loss : 0.337671\n",
      "epoch 0 batch 286 d_loss : 0.352591\n",
      "epoch 0 batch 286 g_loss : 0.451595\n",
      "epoch 0 batch 287 d_loss : 0.418411\n",
      "epoch 0 batch 287 g_loss : 0.514815\n",
      "epoch 0 batch 288 d_loss : 0.429228\n",
      "epoch 0 batch 288 d_loss : 0.294953\n",
      "epoch 0 batch 288 g_loss : 0.452422\n",
      "epoch 0 batch 289 d_loss : 0.376226\n",
      "epoch 0 batch 289 g_loss : 0.494675\n",
      "epoch 0 batch 290 d_loss : 0.326642\n",
      "epoch 0 batch 290 d_loss : 0.399862\n",
      "epoch 0 batch 290 g_loss : 0.486709\n",
      "epoch 0 batch 291 d_loss : 0.354378\n",
      "epoch 0 batch 291 g_loss : 0.523029\n",
      "epoch 0 batch 292 d_loss : 0.321840\n",
      "epoch 0 batch 292 d_loss : 0.344972\n",
      "epoch 0 batch 292 g_loss : 0.398230\n",
      "epoch 0 batch 293 d_loss : 0.331710\n",
      "epoch 0 batch 293 g_loss : 0.401084\n",
      "epoch 0 batch 294 d_loss : 0.342985\n",
      "epoch 0 batch 294 d_loss : 0.373317\n",
      "epoch 0 batch 294 g_loss : 0.391757\n",
      "epoch 0 batch 295 d_loss : 0.420169\n",
      "epoch 0 batch 295 g_loss : 0.471445\n",
      "epoch 0 batch 296 d_loss : 0.326908\n",
      "epoch 0 batch 296 d_loss : 0.277728\n",
      "epoch 0 batch 296 g_loss : 0.418897\n",
      "epoch 0 batch 297 d_loss : 0.430264\n",
      "epoch 0 batch 297 g_loss : 0.519415\n",
      "epoch 0 batch 298 d_loss : 0.398587\n",
      "epoch 0 batch 298 d_loss : 0.367962\n",
      "epoch 0 batch 298 g_loss : 0.382389\n",
      "epoch 0 batch 299 d_loss : 0.398894\n",
      "epoch 0 batch 299 g_loss : 0.444062\n",
      "epoch 0 batch 300 d_loss : 0.322220\n",
      "epoch 0 batch 300 d_loss : 0.382561\n",
      "epoch 0 batch 300 g_loss : 0.468560\n",
      "epoch 0 batch 301 d_loss : 0.359347\n",
      "epoch 0 batch 301 g_loss : 0.410827\n",
      "epoch 0 batch 302 d_loss : 0.384128\n",
      "epoch 0 batch 302 d_loss : 0.343200\n",
      "epoch 0 batch 302 g_loss : 0.535945\n",
      "epoch 0 batch 303 d_loss : 0.389369\n",
      "epoch 0 batch 303 g_loss : 0.461863\n",
      "epoch 0 batch 304 d_loss : 0.410752\n",
      "epoch 0 batch 304 d_loss : 0.297806\n",
      "epoch 0 batch 304 g_loss : 0.484083\n",
      "epoch 0 batch 305 d_loss : 0.286520\n",
      "epoch 0 batch 305 g_loss : 0.402094\n",
      "epoch 0 batch 306 d_loss : 0.368283\n",
      "epoch 0 batch 306 d_loss : 0.330979\n",
      "epoch 0 batch 306 g_loss : 0.430076\n",
      "epoch 0 batch 307 d_loss : 0.360718\n",
      "epoch 0 batch 307 g_loss : 0.391452\n",
      "epoch 0 batch 308 d_loss : 0.365325\n",
      "epoch 0 batch 308 d_loss : 0.322406\n",
      "epoch 0 batch 308 g_loss : 0.443403\n"
     ]
    }
   ],
   "source": [
    "train_another(1000, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_moment = datetime.now()\n",
    "\n",
    "day, month = str(current_moment.day), str(current_moment.month)\n",
    "hour, minute = str(current_moment.hour), str(current_moment.minute)\n",
    "\n",
    "with open(os.getcwd() + '/Changes.txt', 'a') as f:\n",
    "    clock =  (day + '.' + month + '    ' + hour + ':' + minute)\n",
    "    f.write(clock + '...........g_optim -> 0.0003, d_optim->0.0004' + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
