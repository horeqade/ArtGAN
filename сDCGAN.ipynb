{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\Anaconda1\\envs\\NN\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "from scipy.misc.pilutil import imresize, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout, Input\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import initializers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 16 * 8, input_dim = latent_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((8, 8, 256)))\n",
    "        \n",
    "        model.add(Conv2DTranspose(512, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(512, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(256, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(128, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(64, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(32, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(16, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(8, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(img_channels, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(num_classes):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size=filter_size_d, strides = (2,2), input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256,  kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "\n",
    "        features = model(img)\n",
    "\n",
    "        validity = Dense(1)(features)\n",
    "        valid = Activation('sigmoid')(validity)\n",
    "        \n",
    "        label1 = Dense(1024)(features)\n",
    "        lrelu1 = LeakyReLU(alpha=0.2)(label1)\n",
    "        label2 = Dense(512)(label1)\n",
    "        lrelu2 = LeakyReLU(alpha=0.2)(label2)\n",
    "        label3 = Dense(num_classes, name = 'new_layer')(label2)\n",
    "        label = Activation('softmax')(label3)\n",
    "        \n",
    "        return Model(img, valid), Model(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d, d_label):\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = g(noise)\n",
    "    d.trainable = False\n",
    "    d_label.trainable = False\n",
    "    valid, target_label = d(img), d_label(img)\n",
    "    \n",
    "    \n",
    "    return Model(noise, [valid, target_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(epoch, gen):\n",
    "        count = 5\n",
    "        noise = np.random.uniform(-1, 1, size=(count, latent_dim))\n",
    "        gen_imgs = gen.predict(noise)\n",
    "\n",
    "        gen_imgs = 127.5 * gen_imgs + 127.5\n",
    "        \n",
    "        if gen_imgs.shape[3] == 1:\n",
    "            gen_imgs = gen_imgs[:,:,:,0]\n",
    "        \n",
    "        for i in range(count):\n",
    "            cv2.imwrite(os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, i), gen_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(indices, data, batch_size):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    for i in range(batch_size):\n",
    "        if color_mode == 'grayscale':\n",
    "            temp_img = cv2.imread(data[indices[i]], 0)\n",
    "            X_train[i,:,:,0] = temp_img\n",
    "        else:\n",
    "            temp_img = cv2.imread(data[indices[i]])\n",
    "            X_train[i] = temp_img\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_classes(batch_size, data):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size)\n",
    "    choice_arr = np.random.randint(0, len(data), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        rand_number = np.random.randint(0, len(data[choice_arr[i]]))\n",
    "        temp_img = cv2.imread(data[choice_arr[i]][rand_number])\n",
    "        \n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]\n",
    "    \n",
    "\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_one_class(batch_size, data, class_target):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_label = np.zeros(batch_size)\n",
    "    '''choice_arr = np.random.randint(0, len(data[class_target]), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(data[class_target][choice_arr[i]])\n",
    "\n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]'''\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            temp_img = cv2.imread(data[i][j])\n",
    "            \n",
    "            X_train[4*i + j] = temp_img\n",
    "            y_label[4*i + j] = i\n",
    "            \n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], img_channels),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, :,]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(missing_folders):\n",
    "    styles_folder = os.listdir(path=os.getcwd() + \"\\\\new256_images\\\\\")\n",
    "    styles_folder = [style for style in styles_folder if style not in missing_folders]\n",
    "    print(styles_folder)\n",
    "    num_styles = len(styles_folder)\n",
    "    data = []\n",
    "    for i in range(num_styles):\n",
    "        data.append(glob.glob(os.getcwd() + '\\\\new256_images\\\\' + styles_folder[i] + '\\\\*'))\n",
    "    return data, num_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_another(epochs = 100, BATCH_SIZE = 4, weights = False, month_day = '', epoch_ini = 0, missing_folders = []):\n",
    "\n",
    "    data, num_styles = get_data(missing_folders)\n",
    "    \n",
    "    epoch = ' ' + str(epoch_ini) + '_epoch'\n",
    "    \n",
    "    generator = build_generator()\n",
    "    discriminator, d_label = build_discriminator(num_styles)\n",
    "    \n",
    "    discriminator.compile(loss=losses[0], optimizer=d_optim)\n",
    "    d_label.compile(loss=losses[1], optimizer=d_optim)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    \n",
    "    if month_day != '':\n",
    "        generator.load_weights(os.getcwd() + '/weights/' + month_day + epoch + ' gen_weights.h5', by_name = True)\n",
    "        discriminator.load_weights(os.getcwd() + '/weights/' + month_day + epoch + ' dis_weights.h5', by_name = True)\n",
    "        d_label.load_weights(os.getcwd() + '/weights/' + month_day + epoch + ' dis_label_weights.h5', by_name = True)\n",
    "        \n",
    "    \n",
    "    dcgan = generator_containing_discriminator(generator, discriminator, d_label)\n",
    "    \n",
    "    \n",
    "    dcgan.compile(loss=losses[0], optimizer=g_optim)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    d_label.trainable = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(epoch_ini, epochs):\n",
    "        for index in range(int(15000/BATCH_SIZE)):\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "                \n",
    "            #real_images, real_labels = get_images_classes(batch_size=BATCH_SIZE, data = data)\n",
    "            \n",
    "            label = index % num_styles\n",
    "            \n",
    "            real_images, real_labels = get_images_classes(BATCH_SIZE, data)\n",
    "            \n",
    "            #real_images += np.random.normal(size = img_shape, scale= 0.1)\n",
    "            \n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            if index % 2 == 0:\n",
    "                X = real_images\n",
    "                real_labels = real_labels - 0.1 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + real_labels, num_styles)\n",
    "                y = 0.8 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                \n",
    "                d_loss = []\n",
    "                d_loss.append(discriminator.train_on_batch(X, y))\n",
    "                discriminator.trainable = False\n",
    "                d_loss.append(d_label.train_on_batch(X, y_classif))\n",
    "                print(\"epoch %d batch %d d_loss : %f, label_loss: %f\" % (epoch, index, d_loss[0], d_loss[1]))\n",
    "                \n",
    "                X = generated_images\n",
    "                y = np.random.rand(BATCH_SIZE) * 0.2\n",
    "                d_loss = discriminator.train_on_batch(X, y)\n",
    "                \n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss))\n",
    "            else:\n",
    "                X = generated_images\n",
    "                y = np.random.rand(BATCH_SIZE) * 0.2\n",
    "                d_loss = discriminator.train_on_batch(X, y)\n",
    "                \n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss))\n",
    "                \n",
    "                X = real_images\n",
    "                real_labels = real_labels - 0.1 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + real_labels, num_styles)\n",
    "                y = 0.8 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                d_loss = []\n",
    "                d_loss.append(discriminator.train_on_batch(X, y))\n",
    "                discriminator.trainable = False\n",
    "                d_loss.append(d_label.train_on_batch(X, y_classif))\n",
    "                \n",
    "                print(\"epoch %d batch %d d_loss : %f, label_loss: %f\" % (epoch, index, d_loss[0], d_loss[1]))\n",
    "            \n",
    "            \n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "            \n",
    "            discriminator.trainable = False\n",
    "            d_label.trainable = False\n",
    "            \n",
    "            y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + 1/num_styles, num_styles)\n",
    "            y = np.random.rand(BATCH_SIZE) * 0.3\n",
    "            \n",
    "            g_loss = dcgan.train_on_batch(noise, [y, y_classif])\n",
    "            \n",
    "            d_label.trainable = True\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            print(\"epoch %d batch %d g_loss : %f, label_loss: %f\" % (epoch, index, g_loss[0], g_loss[1]))\n",
    "            \n",
    "            if index % 50 == 0:\n",
    "                        image = combine_images(generated_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, index), image)\n",
    "                        image = combine_images(real_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d_data.png' % (epoch, index), image)\n",
    "                        \n",
    "        if epoch % 5 == 0:\n",
    "            \n",
    "            \n",
    "            date_today = date.today()\n",
    "            \n",
    "            \n",
    "            \n",
    "            month, day = date_today.month, date_today.day\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            d_json = discriminator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"/%d.%d dis_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            d_l_json = d_label.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"/%d.%d dis_label_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_l_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            gen_json = generator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"/%d.%d gen_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(gen_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            discriminator.save_weights(os.getcwd() + '/weights/%d.%d %d_epoch dis_weights.h5' % (day, month, epoch))\n",
    "            d_label.save_weights(os.getcwd() + '/weights/%d.%d %d_epoch dis_label_weights.h5' % (day, month, epoch))\n",
    "            generator.save_weights(os.getcwd() + '/weights/%d.%d %d_epoch gen_weights.h5' % (day, month, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "img_channels = 3\n",
    "img_shape = (img_rows, img_cols, img_channels)\n",
    "latent_dim = 100\n",
    "filter_size_g = (5,5)\n",
    "filter_size_d = (5,5)\n",
    "d_strides = (2,2)\n",
    "\n",
    "color_mode = 'rgb'\n",
    "\n",
    "losses = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "\n",
    "\n",
    "#g_optim = SGD(lr = 0.001, momentum=0.9, nesterov=True)\n",
    "#d_optim = SGD(lr = 0.00025, momentum=0.9, nesterov=True)\n",
    "g_optim = Adam(0.0002, beta_2 = 0.5)\n",
    "d_optim = Adam(0.0002, beta_2 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstraktnyy-ekspressionizm', 'kubizm', 'realizm']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 8, 8, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 16, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 64, 64, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 128, 128, 16)      12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 256, 256, 8)       3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256, 256, 8)       32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 256, 256, 3)       603       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 15,926,963\n",
      "Trainable params: 15,891,139\n",
      "Non-trainable params: 35,824\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "=================================================================\n",
      "Total params: 17,422,464\n",
      "Trainable params: 17,418,624\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer #4 (named \"dense_5\"), weight <tf.Variable 'dense_5/kernel:0' shape=(512, 3) dtype=float32_ref> has shape (512, 3), but the saved weight has shape (512, 5).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6b282efdd40d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_another\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth_day\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1.12'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_ini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m205\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'suprematizm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'informel'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-8289da63a373>\u001b[0m in \u001b[0;36mtrain_another\u001b[1;34m(epochs, BATCH_SIZE, weights, month_day, epoch_ini, missing_folders)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/weights/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmonth_day\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' gen_weights.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/weights/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmonth_day\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dis_weights.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0md_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/weights/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmonth_day\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dis_label_weights.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programming\\Anaconda1\\envs\\NN\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 saving.load_weights_from_hdf5_group_by_name(\n\u001b[0;32m   1162\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskip_mismatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m                     reshape=reshape)\n\u001b[0m\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n",
      "\u001b[1;32mD:\\programming\\Anaconda1\\envs\\NN\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[1;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                                          \u001b[1;34m' has shape {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m                                          \u001b[1;34m', but the saved weight has shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m                                          str(weight_values[i].shape) + '.')\n\u001b[0m\u001b[0;32m   1150\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m                     weight_value_tuples.append((symbolic_weights[i],\n",
      "\u001b[1;31mValueError\u001b[0m: Layer #4 (named \"dense_5\"), weight <tf.Variable 'dense_5/kernel:0' shape=(512, 3) dtype=float32_ref> has shape (512, 3), but the saved weight has shape (512, 5)."
     ]
    }
   ],
   "source": [
    "train_another(1000, 16, month_day = '1.12', epoch_ini = 205, missing_folders = ['suprematizm', 'informel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_moment = datetime.now()\n",
    "\n",
    "day, month = str(current_moment.day), str(current_moment.month)\n",
    "hour, minute = str(current_moment.hour), str(current_moment.minute)\n",
    "\n",
    "with open(os.getcwd() + '/Changes.txt', 'a') as f:\n",
    "    clock =  (day + '.' + month + '    ' + hour + ':' + minute)\n",
    "    f.write(clock + '...........g_optim -> 0.0003, d_optim->0.0004' + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
