{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\Anaconda1\\envs\\NN\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "from scipy.misc.pilutil import imresize, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout, Input\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import initializers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 16 * 16, input_dim = latent_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((16, 16, 128)))\n",
    "        model.add(Conv2DTranspose(128, filter_size_g, strides=(4,4), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        '''model.add(Conv2DTranspose(64, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())'''\n",
    "        model.add(Conv2DTranspose(32, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Conv2DTranspose(img_channels, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size=filter_size_d, strides = (2,2), input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(128, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(256,  kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = g(noise)\n",
    "    d.trainable = False\n",
    "    #d_label.trainable = False\n",
    "    valid = d(img)\n",
    "    \n",
    "    \n",
    "    return Model(noise, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(epoch, gen):\n",
    "        count = 5\n",
    "        noise = np.random.uniform(-1, 1, size=(count, latent_dim))\n",
    "        gen_imgs = gen.predict(noise)\n",
    "\n",
    "        gen_imgs = 127.5 * gen_imgs + 127.5\n",
    "        \n",
    "        if gen_imgs.shape[3] == 1:\n",
    "            gen_imgs = gen_imgs[:,:,:,0]\n",
    "        \n",
    "        for i in range(count):\n",
    "            cv2.imwrite(os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, i), gen_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(indices, data, batch_size):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    for i in range(batch_size):\n",
    "        if color_mode == 'grayscale':\n",
    "            temp_img = cv2.imread(data[indices[i]], 0)\n",
    "            X_train[i,:,:,0] = temp_img\n",
    "        else:\n",
    "            temp_img = cv2.imread(data[indices[i]])\n",
    "            X_train[i] = temp_img\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_classes(batch_size, data):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size)\n",
    "    choice_arr = np.random.randint(0, len(data), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        rand_number = np.random.randint(0, len(data[choice_arr[i]]))\n",
    "        temp_img = cv2.imread(data[choice_arr[i]][rand_number])\n",
    "        \n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]\n",
    "    \n",
    "\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_one_class(batch_size, data, class_target):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size) + class_target\n",
    "    '''choice_arr = np.random.randint(0, len(data[class_target]), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(data[class_target][choice_arr[i]])\n",
    "\n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]'''\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(os.getcwd() + '/new256_images/abstraktnyy-ekspressionizm/303.png')\n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = 0\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], img_channels),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, :,]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    styles_folder = os.listdir(path=os.getcwd() + \"\\\\new256_images\\\\\")\n",
    "    num_styles = len(styles_folder)\n",
    "    data = []\n",
    "    for i in range(num_styles):\n",
    "        data.append(glob.glob(os.getcwd() + '\\\\new256_images\\\\' + styles_folder[i] + '\\\\*'))\n",
    "    return data, num_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_another(epochs = 100, BATCH_SIZE = 4):\n",
    "\n",
    "    data, num_styles = get_data()\n",
    "    \n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    discriminator.compile(loss=losses[0], optimizer=d_optim)\n",
    "    #d_label.compile(loss=losses[1], optimizer=d_optim)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    dcgan = generator_containing_discriminator(generator, discriminator)\n",
    "    \n",
    "    \n",
    "    dcgan.compile(loss=losses[0], optimizer=g_optim)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    #d_label.trainable = True\n",
    "    \n",
    "    \n",
    "    '''(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))'''\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for index in range(int(15000/BATCH_SIZE)):\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "                \n",
    "            #real_images, real_labels = get_images_classes(batch_size=BATCH_SIZE, data = data)\n",
    "            \n",
    "            label = index % num_styles\n",
    "            \n",
    "            real_images, real_labels = get_images_one_class(BATCH_SIZE, data, label)\n",
    "            \n",
    "            real_images += np.random.normal(size = img_shape, scale= 0.1)\n",
    "            \n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            if index % 2 == 0:\n",
    "                X = real_images\n",
    "                real_labels = real_labels - 0.1 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + label, num_styles)\n",
    "                y = 0.8 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                \n",
    "                d_loss = []\n",
    "                d_loss.append(discriminator.train_on_batch(X, y))\n",
    "                #discriminator.trainable = False\n",
    "                #d_loss.append(d_label.train_on_batch(X, y_classif))\n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss[0]))\n",
    "            else:\n",
    "                X = generated_images\n",
    "                y = np.random.rand(BATCH_SIZE) * 0.2\n",
    "                d_loss = discriminator.train_on_batch(X, y)\n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss))\n",
    "            \n",
    "            \n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "            \n",
    "            discriminator.trainable = False\n",
    "            #d_label.trainable = False\n",
    "            \n",
    "            y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + 0.5, num_styles)\n",
    "            y = np.random.rand(BATCH_SIZE) * 0.3\n",
    "            \n",
    "            g_loss = dcgan.train_on_batch(noise, y)\n",
    "            \n",
    "            #d_label.trainable = True\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            print(\"epoch %d batch %d g_loss : %f\" % (epoch, index, g_loss))\n",
    "            \n",
    "            if index % 50 == 0:\n",
    "                        image = combine_images(generated_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, index), image)\n",
    "                        image = combine_images(real_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d_data.png' % (epoch, index), image)\n",
    "                        \n",
    "        if epoch % 5 == 0:\n",
    "            \n",
    "            \n",
    "            date_today = date.today()\n",
    "            \n",
    "            \n",
    "            \n",
    "            month, day = date_today.month, date_today.day\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            d_json = discriminator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d dis_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            '''# Генерируем описание модели в формате json\n",
    "            d_l_json = d_label.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d dis_label_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_l_json)\n",
    "            json_file.close()'''\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            gen_json = generator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d gen_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(gen_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            discriminator.save_weights(os.getcwd() + '%d.%d dis_weights.h5' % (day, month))\n",
    "            #d_label.save_weights(os.getcwd() + '%d.%d dis_label_weights.h5' % (day, month))\n",
    "            generator.save_weights(os.getcwd() + '%d.%d gen_weights.h5' % (day, month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "img_channels = 3\n",
    "img_shape = (img_rows, img_cols, img_channels)\n",
    "latent_dim = 100\n",
    "filter_size_g = (5,5)\n",
    "filter_size_d = (5,5)\n",
    "d_strides = (2,2)\n",
    "\n",
    "color_mode = 'rgb'\n",
    "\n",
    "losses = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "\n",
    "\n",
    "#g_optim = SGD(lr = 0.001, momentum=0.9, nesterov=True)\n",
    "#d_optim = SGD(lr = 0.00025, momentum=0.9, nesterov=True)\n",
    "g_optim = Adam(0.0002, beta_2 = 0.5)\n",
    "d_optim = Adam(0.00015, beta_2 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32768)             3309568   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32768)             131072    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 32)      102432    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 256, 256, 3)       2403      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 3,955,843\n",
      "Trainable params: 3,889,987\n",
      "Non-trainable params: 65,856\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,430,657\n",
      "Trainable params: 17,426,817\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "epoch 0 batch 0 d_loss : 0.557816\n",
      "epoch 0 batch 0 g_loss : 1.894237\n",
      "epoch 0 batch 1 d_loss : 1.984459\n",
      "epoch 0 batch 1 g_loss : 0.563378\n",
      "epoch 0 batch 2 d_loss : 1.748899\n",
      "epoch 0 batch 2 g_loss : 0.878030\n",
      "epoch 0 batch 3 d_loss : 0.656949\n",
      "epoch 0 batch 3 g_loss : 0.891291\n",
      "epoch 0 batch 4 d_loss : 1.609012\n",
      "epoch 0 batch 4 g_loss : 1.473284\n",
      "epoch 0 batch 5 d_loss : 0.658558\n",
      "epoch 0 batch 5 g_loss : 2.272422\n",
      "epoch 0 batch 6 d_loss : 1.707239\n",
      "epoch 0 batch 6 g_loss : 1.870007\n",
      "epoch 0 batch 7 d_loss : 1.162349\n",
      "epoch 0 batch 7 g_loss : 1.452048\n",
      "epoch 0 batch 8 d_loss : 1.777348\n",
      "epoch 0 batch 8 g_loss : 1.749267\n",
      "epoch 0 batch 9 d_loss : 1.711719\n",
      "epoch 0 batch 9 g_loss : 1.462379\n",
      "epoch 0 batch 10 d_loss : 1.321242\n",
      "epoch 0 batch 10 g_loss : 1.315251\n",
      "epoch 0 batch 11 d_loss : 0.884182\n",
      "epoch 0 batch 11 g_loss : 1.797439\n",
      "epoch 0 batch 12 d_loss : 1.404101\n",
      "epoch 0 batch 12 g_loss : 1.569908\n",
      "epoch 0 batch 13 d_loss : 1.294286\n",
      "epoch 0 batch 13 g_loss : 1.880318\n",
      "epoch 0 batch 14 d_loss : 1.450953\n",
      "epoch 0 batch 14 g_loss : 1.681096\n",
      "epoch 0 batch 15 d_loss : 1.532114\n",
      "epoch 0 batch 15 g_loss : 1.924562\n",
      "epoch 0 batch 16 d_loss : 1.630692\n",
      "epoch 0 batch 16 g_loss : 1.940900\n",
      "epoch 0 batch 17 d_loss : 1.299543\n",
      "epoch 0 batch 17 g_loss : 1.745946\n",
      "epoch 0 batch 18 d_loss : 1.977148\n",
      "epoch 0 batch 18 g_loss : 2.011655\n",
      "epoch 0 batch 19 d_loss : 1.940145\n",
      "epoch 0 batch 19 g_loss : 2.305989\n",
      "epoch 0 batch 20 d_loss : 1.509570\n",
      "epoch 0 batch 20 g_loss : 2.066425\n",
      "epoch 0 batch 21 d_loss : 1.755763\n",
      "epoch 0 batch 21 g_loss : 1.739382\n",
      "epoch 0 batch 22 d_loss : 1.436182\n",
      "epoch 0 batch 22 g_loss : 2.387640\n",
      "epoch 0 batch 23 d_loss : 1.214348\n",
      "epoch 0 batch 23 g_loss : 2.184918\n",
      "epoch 0 batch 24 d_loss : 6.916598\n",
      "epoch 0 batch 24 g_loss : 1.865106\n",
      "epoch 0 batch 25 d_loss : 1.443791\n",
      "epoch 0 batch 25 g_loss : 1.674508\n",
      "epoch 0 batch 26 d_loss : 0.953330\n",
      "epoch 0 batch 26 g_loss : 2.611241\n",
      "epoch 0 batch 27 d_loss : 1.839012\n",
      "epoch 0 batch 27 g_loss : 2.214820\n",
      "epoch 0 batch 28 d_loss : 1.313663\n",
      "epoch 0 batch 28 g_loss : 1.773455\n",
      "epoch 0 batch 29 d_loss : 1.518711\n",
      "epoch 0 batch 29 g_loss : 1.788337\n",
      "epoch 0 batch 30 d_loss : 1.573742\n",
      "epoch 0 batch 30 g_loss : 2.413269\n",
      "epoch 0 batch 31 d_loss : 1.787138\n",
      "epoch 0 batch 31 g_loss : 2.963439\n",
      "epoch 0 batch 32 d_loss : 1.595489\n",
      "epoch 0 batch 32 g_loss : 2.440772\n",
      "epoch 0 batch 33 d_loss : 1.724542\n",
      "epoch 0 batch 33 g_loss : 2.205748\n",
      "epoch 0 batch 34 d_loss : 1.352083\n",
      "epoch 0 batch 34 g_loss : 1.669711\n",
      "epoch 0 batch 35 d_loss : 1.435850\n",
      "epoch 0 batch 35 g_loss : 1.764878\n",
      "epoch 0 batch 36 d_loss : 1.708863\n",
      "epoch 0 batch 36 g_loss : 1.826801\n",
      "epoch 0 batch 37 d_loss : 1.466153\n",
      "epoch 0 batch 37 g_loss : 1.835685\n",
      "epoch 0 batch 38 d_loss : 1.874115\n",
      "epoch 0 batch 38 g_loss : 2.357407\n",
      "epoch 0 batch 39 d_loss : 1.246829\n",
      "epoch 0 batch 39 g_loss : 2.084269\n",
      "epoch 0 batch 40 d_loss : 1.278965\n",
      "epoch 0 batch 40 g_loss : 1.679069\n",
      "epoch 0 batch 41 d_loss : 1.225219\n",
      "epoch 0 batch 41 g_loss : 2.110010\n",
      "epoch 0 batch 42 d_loss : 1.507419\n",
      "epoch 0 batch 42 g_loss : 1.795018\n",
      "epoch 0 batch 43 d_loss : 1.585857\n",
      "epoch 0 batch 43 g_loss : 1.812613\n",
      "epoch 0 batch 44 d_loss : 1.392061\n",
      "epoch 0 batch 44 g_loss : 1.640236\n",
      "epoch 0 batch 45 d_loss : 0.913930\n",
      "epoch 0 batch 45 g_loss : 1.886803\n",
      "epoch 0 batch 46 d_loss : 1.763788\n",
      "epoch 0 batch 46 g_loss : 1.137608\n",
      "epoch 0 batch 47 d_loss : 1.193387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 47 g_loss : 1.169052\n",
      "epoch 0 batch 48 d_loss : 1.606939\n",
      "epoch 0 batch 48 g_loss : 1.558531\n",
      "epoch 0 batch 49 d_loss : 0.961804\n",
      "epoch 0 batch 49 g_loss : 1.429942\n",
      "epoch 0 batch 50 d_loss : 1.437460\n",
      "epoch 0 batch 50 g_loss : 1.019150\n",
      "epoch 0 batch 51 d_loss : 0.972357\n",
      "epoch 0 batch 51 g_loss : 1.133094\n",
      "epoch 0 batch 52 d_loss : 1.556081\n",
      "epoch 0 batch 52 g_loss : 0.994541\n",
      "epoch 0 batch 53 d_loss : 0.951756\n",
      "epoch 0 batch 53 g_loss : 1.198649\n",
      "epoch 0 batch 54 d_loss : 0.841061\n",
      "epoch 0 batch 54 g_loss : 0.916904\n",
      "epoch 0 batch 55 d_loss : 0.705350\n",
      "epoch 0 batch 55 g_loss : 1.263614\n",
      "epoch 0 batch 56 d_loss : 1.408950\n",
      "epoch 0 batch 56 g_loss : 0.980341\n",
      "epoch 0 batch 57 d_loss : 0.708519\n",
      "epoch 0 batch 57 g_loss : 0.915262\n",
      "epoch 0 batch 58 d_loss : 0.368338\n",
      "epoch 0 batch 58 g_loss : 0.900022\n",
      "epoch 0 batch 59 d_loss : 0.592485\n",
      "epoch 0 batch 59 g_loss : 0.734335\n",
      "epoch 0 batch 60 d_loss : 0.910416\n",
      "epoch 0 batch 60 g_loss : 0.958834\n",
      "epoch 0 batch 61 d_loss : 0.627946\n",
      "epoch 0 batch 61 g_loss : 1.179638\n",
      "epoch 0 batch 62 d_loss : 1.075869\n",
      "epoch 0 batch 62 g_loss : 0.607670\n",
      "epoch 0 batch 63 d_loss : 0.534963\n",
      "epoch 0 batch 63 g_loss : 0.906652\n",
      "epoch 0 batch 64 d_loss : 1.157948\n",
      "epoch 0 batch 64 g_loss : 0.649361\n",
      "epoch 0 batch 65 d_loss : 0.514479\n",
      "epoch 0 batch 65 g_loss : 0.635069\n",
      "epoch 0 batch 66 d_loss : 1.123467\n",
      "epoch 0 batch 66 g_loss : 0.652250\n",
      "epoch 0 batch 67 d_loss : 0.509398\n",
      "epoch 0 batch 67 g_loss : 0.556387\n",
      "epoch 0 batch 68 d_loss : 0.827145\n",
      "epoch 0 batch 68 g_loss : 0.658280\n",
      "epoch 0 batch 69 d_loss : 0.429902\n",
      "epoch 0 batch 69 g_loss : 0.622133\n",
      "epoch 0 batch 70 d_loss : 0.314744\n",
      "epoch 0 batch 70 g_loss : 0.519810\n",
      "epoch 0 batch 71 d_loss : 0.438870\n",
      "epoch 0 batch 71 g_loss : 0.457020\n",
      "epoch 0 batch 72 d_loss : 2.285169\n",
      "epoch 0 batch 72 g_loss : 0.568577\n",
      "epoch 0 batch 73 d_loss : 0.383627\n",
      "epoch 0 batch 73 g_loss : 0.555229\n",
      "epoch 0 batch 74 d_loss : 0.922697\n",
      "epoch 0 batch 74 g_loss : 0.547633\n",
      "epoch 0 batch 75 d_loss : 0.608740\n",
      "epoch 0 batch 75 g_loss : 0.543769\n",
      "epoch 0 batch 76 d_loss : 0.313180\n",
      "epoch 0 batch 76 g_loss : 0.386266\n",
      "epoch 0 batch 77 d_loss : 0.472909\n",
      "epoch 0 batch 77 g_loss : 0.498010\n",
      "epoch 0 batch 78 d_loss : 0.716434\n",
      "epoch 0 batch 78 g_loss : 0.560209\n",
      "epoch 0 batch 79 d_loss : 0.482978\n",
      "epoch 0 batch 79 g_loss : 0.563756\n",
      "epoch 0 batch 80 d_loss : 1.004658\n",
      "epoch 0 batch 80 g_loss : 0.536541\n",
      "epoch 0 batch 81 d_loss : 0.494503\n",
      "epoch 0 batch 81 g_loss : 0.556270\n",
      "epoch 0 batch 82 d_loss : 1.352396\n",
      "epoch 0 batch 82 g_loss : 0.448606\n",
      "epoch 0 batch 83 d_loss : 0.451275\n",
      "epoch 0 batch 83 g_loss : 0.575238\n",
      "epoch 0 batch 84 d_loss : 1.324798\n",
      "epoch 0 batch 84 g_loss : 0.475061\n",
      "epoch 0 batch 85 d_loss : 0.424842\n",
      "epoch 0 batch 85 g_loss : 0.638389\n",
      "epoch 0 batch 86 d_loss : 1.604602\n",
      "epoch 0 batch 86 g_loss : 0.656507\n",
      "epoch 0 batch 87 d_loss : 0.522053\n",
      "epoch 0 batch 87 g_loss : 0.636384\n",
      "epoch 0 batch 88 d_loss : 1.275603\n",
      "epoch 0 batch 88 g_loss : 0.589133\n",
      "epoch 0 batch 89 d_loss : 0.414892\n",
      "epoch 0 batch 89 g_loss : 0.610046\n",
      "epoch 0 batch 90 d_loss : 1.087817\n",
      "epoch 0 batch 90 g_loss : 0.472613\n",
      "epoch 0 batch 91 d_loss : 0.442720\n",
      "epoch 0 batch 91 g_loss : 0.630056\n",
      "epoch 0 batch 92 d_loss : 0.932568\n",
      "epoch 0 batch 92 g_loss : 0.574114\n",
      "epoch 0 batch 93 d_loss : 0.400703\n",
      "epoch 0 batch 93 g_loss : 0.654871\n",
      "epoch 0 batch 94 d_loss : 0.604854\n",
      "epoch 0 batch 94 g_loss : 0.640947\n",
      "epoch 0 batch 95 d_loss : 0.434630\n",
      "epoch 0 batch 95 g_loss : 0.602106\n",
      "epoch 0 batch 96 d_loss : 0.526453\n",
      "epoch 0 batch 96 g_loss : 0.473137\n",
      "epoch 0 batch 97 d_loss : 0.369955\n",
      "epoch 0 batch 97 g_loss : 0.408520\n",
      "epoch 0 batch 98 d_loss : 0.439771\n",
      "epoch 0 batch 98 g_loss : 0.513455\n",
      "epoch 0 batch 99 d_loss : 0.295590\n",
      "epoch 0 batch 99 g_loss : 0.486932\n",
      "epoch 0 batch 100 d_loss : 0.538085\n",
      "epoch 0 batch 100 g_loss : 0.388536\n",
      "epoch 0 batch 101 d_loss : 0.369665\n",
      "epoch 0 batch 101 g_loss : 0.528038\n",
      "epoch 0 batch 102 d_loss : 0.363865\n",
      "epoch 0 batch 102 g_loss : 0.408741\n",
      "epoch 0 batch 103 d_loss : 0.392462\n",
      "epoch 0 batch 103 g_loss : 0.547416\n",
      "epoch 0 batch 104 d_loss : 0.314421\n",
      "epoch 0 batch 104 g_loss : 0.514326\n",
      "epoch 0 batch 105 d_loss : 0.339118\n",
      "epoch 0 batch 105 g_loss : 0.418541\n",
      "epoch 0 batch 106 d_loss : 0.439917\n",
      "epoch 0 batch 106 g_loss : 0.471873\n",
      "epoch 0 batch 107 d_loss : 0.346188\n",
      "epoch 0 batch 107 g_loss : 0.451018\n",
      "epoch 0 batch 108 d_loss : 0.492923\n",
      "epoch 0 batch 108 g_loss : 0.532948\n",
      "epoch 0 batch 109 d_loss : 0.361180\n",
      "epoch 0 batch 109 g_loss : 0.424582\n",
      "epoch 0 batch 110 d_loss : 0.429780\n",
      "epoch 0 batch 110 g_loss : 0.495027\n",
      "epoch 0 batch 111 d_loss : 0.349692\n",
      "epoch 0 batch 111 g_loss : 0.464003\n",
      "epoch 0 batch 112 d_loss : 0.581111\n",
      "epoch 0 batch 112 g_loss : 0.402352\n",
      "epoch 0 batch 113 d_loss : 0.306485\n",
      "epoch 0 batch 113 g_loss : 0.368800\n",
      "epoch 0 batch 114 d_loss : 0.381927\n",
      "epoch 0 batch 114 g_loss : 0.377362\n",
      "epoch 0 batch 115 d_loss : 0.386449\n",
      "epoch 0 batch 115 g_loss : 0.482991\n",
      "epoch 0 batch 116 d_loss : 0.345105\n",
      "epoch 0 batch 116 g_loss : 0.475026\n",
      "epoch 0 batch 117 d_loss : 0.347242\n",
      "epoch 0 batch 117 g_loss : 0.517399\n",
      "epoch 0 batch 118 d_loss : 0.474120\n",
      "epoch 0 batch 118 g_loss : 0.486006\n",
      "epoch 0 batch 119 d_loss : 0.339799\n",
      "epoch 0 batch 119 g_loss : 0.388201\n",
      "epoch 0 batch 120 d_loss : 0.384256\n",
      "epoch 0 batch 120 g_loss : 0.457208\n",
      "epoch 0 batch 121 d_loss : 0.393653\n",
      "epoch 0 batch 121 g_loss : 0.495249\n",
      "epoch 0 batch 122 d_loss : 0.287365\n",
      "epoch 0 batch 122 g_loss : 0.450856\n",
      "epoch 0 batch 123 d_loss : 0.335141\n",
      "epoch 0 batch 123 g_loss : 0.361139\n",
      "epoch 0 batch 124 d_loss : 0.427964\n",
      "epoch 0 batch 124 g_loss : 0.439567\n",
      "epoch 0 batch 125 d_loss : 0.315927\n",
      "epoch 0 batch 125 g_loss : 0.467918\n",
      "epoch 0 batch 126 d_loss : 0.544231\n",
      "epoch 0 batch 126 g_loss : 0.494572\n",
      "epoch 0 batch 127 d_loss : 0.345880\n",
      "epoch 0 batch 127 g_loss : 0.462361\n",
      "epoch 0 batch 128 d_loss : 0.404473\n",
      "epoch 0 batch 128 g_loss : 0.406518\n",
      "epoch 0 batch 129 d_loss : 0.349408\n",
      "epoch 0 batch 129 g_loss : 0.428491\n",
      "epoch 0 batch 130 d_loss : 0.388694\n",
      "epoch 0 batch 130 g_loss : 0.449834\n",
      "epoch 0 batch 131 d_loss : 0.334959\n",
      "epoch 0 batch 131 g_loss : 0.437326\n",
      "epoch 0 batch 132 d_loss : 0.327655\n",
      "epoch 0 batch 132 g_loss : 0.460228\n",
      "epoch 0 batch 133 d_loss : 0.268786\n",
      "epoch 0 batch 133 g_loss : 0.471076\n",
      "epoch 0 batch 134 d_loss : 0.592001\n",
      "epoch 0 batch 134 g_loss : 0.439133\n",
      "epoch 0 batch 135 d_loss : 0.353250\n",
      "epoch 0 batch 135 g_loss : 0.430286\n",
      "epoch 0 batch 136 d_loss : 0.469862\n",
      "epoch 0 batch 136 g_loss : 0.435471\n",
      "epoch 0 batch 137 d_loss : 0.339361\n",
      "epoch 0 batch 137 g_loss : 0.446747\n",
      "epoch 0 batch 138 d_loss : 0.323522\n",
      "epoch 0 batch 138 g_loss : 0.479553\n",
      "epoch 0 batch 139 d_loss : 0.339074\n",
      "epoch 0 batch 139 g_loss : 0.521168\n",
      "epoch 0 batch 140 d_loss : 0.402117\n",
      "epoch 0 batch 140 g_loss : 0.465206\n",
      "epoch 0 batch 141 d_loss : 0.313380\n",
      "epoch 0 batch 141 g_loss : 0.437918\n",
      "epoch 0 batch 142 d_loss : 0.400825\n",
      "epoch 0 batch 142 g_loss : 0.465166\n",
      "epoch 0 batch 143 d_loss : 0.327562\n",
      "epoch 0 batch 143 g_loss : 0.499454\n",
      "epoch 0 batch 144 d_loss : 0.594422\n",
      "epoch 0 batch 144 g_loss : 0.438398\n",
      "epoch 0 batch 145 d_loss : 0.335379\n",
      "epoch 0 batch 145 g_loss : 0.518853\n",
      "epoch 0 batch 146 d_loss : 0.445822\n",
      "epoch 0 batch 146 g_loss : 0.450709\n",
      "epoch 0 batch 147 d_loss : 0.396299\n",
      "epoch 0 batch 147 g_loss : 0.448144\n",
      "epoch 0 batch 148 d_loss : 0.507772\n",
      "epoch 0 batch 148 g_loss : 0.414506\n",
      "epoch 0 batch 149 d_loss : 0.269248\n",
      "epoch 0 batch 149 g_loss : 0.520651\n",
      "epoch 0 batch 150 d_loss : 0.444930\n",
      "epoch 0 batch 150 g_loss : 0.432548\n",
      "epoch 0 batch 151 d_loss : 0.346940\n",
      "epoch 0 batch 151 g_loss : 0.439432\n",
      "epoch 0 batch 152 d_loss : 0.355990\n",
      "epoch 0 batch 152 g_loss : 0.455257\n",
      "epoch 0 batch 153 d_loss : 0.345829\n",
      "epoch 0 batch 153 g_loss : 0.417070\n",
      "epoch 0 batch 154 d_loss : 0.588455\n",
      "epoch 0 batch 154 g_loss : 0.503091\n",
      "epoch 0 batch 155 d_loss : 0.349607\n",
      "epoch 0 batch 155 g_loss : 0.394337\n",
      "epoch 0 batch 156 d_loss : 0.508675\n",
      "epoch 0 batch 156 g_loss : 0.502879\n",
      "epoch 0 batch 157 d_loss : 0.287543\n",
      "epoch 0 batch 157 g_loss : 0.389641\n",
      "epoch 0 batch 158 d_loss : 0.348909\n",
      "epoch 0 batch 158 g_loss : 0.444898\n",
      "epoch 0 batch 159 d_loss : 0.323600\n",
      "epoch 0 batch 159 g_loss : 0.417428\n",
      "epoch 0 batch 160 d_loss : 0.400755\n",
      "epoch 0 batch 160 g_loss : 0.437439\n",
      "epoch 0 batch 161 d_loss : 0.316733\n",
      "epoch 0 batch 161 g_loss : 0.435438\n",
      "epoch 0 batch 162 d_loss : 0.432373\n",
      "epoch 0 batch 162 g_loss : 0.462652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 163 d_loss : 0.335612\n",
      "epoch 0 batch 163 g_loss : 0.433610\n",
      "epoch 0 batch 164 d_loss : 0.591455\n",
      "epoch 0 batch 164 g_loss : 0.432603\n",
      "epoch 0 batch 165 d_loss : 0.343181\n",
      "epoch 0 batch 165 g_loss : 0.456221\n",
      "epoch 0 batch 166 d_loss : 0.542898\n",
      "epoch 0 batch 166 g_loss : 0.394333\n",
      "epoch 0 batch 167 d_loss : 0.361306\n",
      "epoch 0 batch 167 g_loss : 0.417765\n",
      "epoch 0 batch 168 d_loss : 0.375572\n",
      "epoch 0 batch 168 g_loss : 0.458156\n",
      "epoch 0 batch 169 d_loss : 0.330279\n",
      "epoch 0 batch 169 g_loss : 0.441799\n",
      "epoch 0 batch 170 d_loss : 0.312093\n",
      "epoch 0 batch 170 g_loss : 0.450540\n",
      "epoch 0 batch 171 d_loss : 0.318149\n",
      "epoch 0 batch 171 g_loss : 0.471840\n",
      "epoch 0 batch 172 d_loss : 0.348950\n",
      "epoch 0 batch 172 g_loss : 0.465299\n",
      "epoch 0 batch 173 d_loss : 0.372780\n",
      "epoch 0 batch 173 g_loss : 0.444903\n",
      "epoch 0 batch 174 d_loss : 0.714332\n",
      "epoch 0 batch 174 g_loss : 0.430066\n",
      "epoch 0 batch 175 d_loss : 0.334759\n",
      "epoch 0 batch 175 g_loss : 0.464739\n",
      "epoch 0 batch 176 d_loss : 0.560411\n",
      "epoch 0 batch 176 g_loss : 0.473414\n",
      "epoch 0 batch 177 d_loss : 0.366818\n",
      "epoch 0 batch 177 g_loss : 0.474471\n",
      "epoch 0 batch 178 d_loss : 0.378798\n",
      "epoch 0 batch 178 g_loss : 0.445592\n",
      "epoch 0 batch 179 d_loss : 0.363218\n",
      "epoch 0 batch 179 g_loss : 0.468893\n",
      "epoch 0 batch 180 d_loss : 0.387169\n",
      "epoch 0 batch 180 g_loss : 0.479954\n",
      "epoch 0 batch 181 d_loss : 0.364833\n",
      "epoch 0 batch 181 g_loss : 0.543909\n",
      "epoch 0 batch 182 d_loss : 0.341438\n",
      "epoch 0 batch 182 g_loss : 0.497481\n",
      "epoch 0 batch 183 d_loss : 0.343246\n",
      "epoch 0 batch 183 g_loss : 0.473091\n",
      "epoch 0 batch 184 d_loss : 0.701927\n",
      "epoch 0 batch 184 g_loss : 0.530702\n",
      "epoch 0 batch 185 d_loss : 0.341002\n",
      "epoch 0 batch 185 g_loss : 0.456238\n",
      "epoch 0 batch 186 d_loss : 0.591342\n",
      "epoch 0 batch 186 g_loss : 0.415010\n",
      "epoch 0 batch 187 d_loss : 0.325030\n",
      "epoch 0 batch 187 g_loss : 0.484461\n",
      "epoch 0 batch 188 d_loss : 0.606458\n",
      "epoch 0 batch 188 g_loss : 0.381258\n",
      "epoch 0 batch 189 d_loss : 0.366229\n",
      "epoch 0 batch 189 g_loss : 0.551242\n",
      "epoch 0 batch 190 d_loss : 0.614074\n",
      "epoch 0 batch 190 g_loss : 0.367591\n",
      "epoch 0 batch 191 d_loss : 0.337152\n",
      "epoch 0 batch 191 g_loss : 0.426577\n",
      "epoch 0 batch 192 d_loss : 0.426793\n",
      "epoch 0 batch 192 g_loss : 0.524077\n",
      "epoch 0 batch 193 d_loss : 0.309809\n",
      "epoch 0 batch 193 g_loss : 0.484156\n",
      "epoch 0 batch 194 d_loss : 0.470241\n",
      "epoch 0 batch 194 g_loss : 0.543369\n",
      "epoch 0 batch 195 d_loss : 0.369969\n",
      "epoch 0 batch 195 g_loss : 0.440663\n",
      "epoch 0 batch 196 d_loss : 0.371844\n",
      "epoch 0 batch 196 g_loss : 0.391628\n",
      "epoch 0 batch 197 d_loss : 0.315294\n",
      "epoch 0 batch 197 g_loss : 0.437319\n",
      "epoch 0 batch 198 d_loss : 0.668373\n",
      "epoch 0 batch 198 g_loss : 0.450844\n",
      "epoch 0 batch 199 d_loss : 0.318734\n",
      "epoch 0 batch 199 g_loss : 0.390036\n",
      "epoch 0 batch 200 d_loss : 0.555288\n",
      "epoch 0 batch 200 g_loss : 0.450459\n",
      "epoch 0 batch 201 d_loss : 0.344248\n",
      "epoch 0 batch 201 g_loss : 0.504882\n",
      "epoch 0 batch 202 d_loss : 0.363315\n",
      "epoch 0 batch 202 g_loss : 0.571126\n",
      "epoch 0 batch 203 d_loss : 0.356321\n",
      "epoch 0 batch 203 g_loss : 0.467237\n",
      "epoch 0 batch 204 d_loss : 0.319630\n",
      "epoch 0 batch 204 g_loss : 0.412621\n",
      "epoch 0 batch 205 d_loss : 0.368203\n",
      "epoch 0 batch 205 g_loss : 0.530477\n",
      "epoch 0 batch 206 d_loss : 0.391781\n",
      "epoch 0 batch 206 g_loss : 0.544480\n",
      "epoch 0 batch 207 d_loss : 0.287049\n",
      "epoch 0 batch 207 g_loss : 0.444229\n",
      "epoch 0 batch 208 d_loss : 0.551317\n",
      "epoch 0 batch 208 g_loss : 0.552111\n",
      "epoch 0 batch 209 d_loss : 0.345749\n",
      "epoch 0 batch 209 g_loss : 0.396306\n",
      "epoch 0 batch 210 d_loss : 0.601300\n",
      "epoch 0 batch 210 g_loss : 0.464442\n",
      "epoch 0 batch 211 d_loss : 0.362852\n",
      "epoch 0 batch 211 g_loss : 0.480085\n",
      "epoch 0 batch 212 d_loss : 0.653538\n",
      "epoch 0 batch 212 g_loss : 0.415270\n",
      "epoch 0 batch 213 d_loss : 0.377883\n",
      "epoch 0 batch 213 g_loss : 0.418204\n",
      "epoch 0 batch 214 d_loss : 0.616348\n",
      "epoch 0 batch 214 g_loss : 0.532763\n",
      "epoch 0 batch 215 d_loss : 0.311832\n",
      "epoch 0 batch 215 g_loss : 0.433913\n",
      "epoch 0 batch 216 d_loss : 0.424461\n",
      "epoch 0 batch 216 g_loss : 0.410640\n",
      "epoch 0 batch 217 d_loss : 0.334917\n",
      "epoch 0 batch 217 g_loss : 0.439453\n",
      "epoch 0 batch 218 d_loss : 0.377340\n",
      "epoch 0 batch 218 g_loss : 0.418180\n",
      "epoch 0 batch 219 d_loss : 0.376898\n",
      "epoch 0 batch 219 g_loss : 0.490370\n",
      "epoch 0 batch 220 d_loss : 0.321251\n",
      "epoch 0 batch 220 g_loss : 0.463029\n",
      "epoch 0 batch 221 d_loss : 0.306905\n",
      "epoch 0 batch 221 g_loss : 0.436728\n",
      "epoch 0 batch 222 d_loss : 0.610847\n",
      "epoch 0 batch 222 g_loss : 0.417310\n",
      "epoch 0 batch 223 d_loss : 0.336115\n",
      "epoch 0 batch 223 g_loss : 0.506492\n",
      "epoch 0 batch 224 d_loss : 0.519422\n",
      "epoch 0 batch 224 g_loss : 0.503998\n",
      "epoch 0 batch 225 d_loss : 0.276287\n",
      "epoch 0 batch 225 g_loss : 0.467182\n",
      "epoch 0 batch 226 d_loss : 0.393079\n",
      "epoch 0 batch 226 g_loss : 0.601053\n",
      "epoch 0 batch 227 d_loss : 0.383787\n",
      "epoch 0 batch 227 g_loss : 0.450297\n",
      "epoch 0 batch 228 d_loss : 0.313273\n",
      "epoch 0 batch 228 g_loss : 0.533564\n",
      "epoch 0 batch 229 d_loss : 0.318391\n",
      "epoch 0 batch 229 g_loss : 0.504495\n",
      "epoch 0 batch 230 d_loss : 0.329632\n",
      "epoch 0 batch 230 g_loss : 0.526558\n",
      "epoch 0 batch 231 d_loss : 0.315954\n",
      "epoch 0 batch 231 g_loss : 0.446162\n",
      "epoch 0 batch 232 d_loss : 0.622306\n",
      "epoch 0 batch 232 g_loss : 0.510047\n",
      "epoch 0 batch 233 d_loss : 0.346945\n",
      "epoch 0 batch 233 g_loss : 0.437669\n",
      "epoch 0 batch 234 d_loss : 0.572643\n",
      "epoch 0 batch 234 g_loss : 0.467679\n",
      "epoch 0 batch 235 d_loss : 0.358695\n",
      "epoch 0 batch 235 g_loss : 0.474996\n",
      "epoch 0 batch 236 d_loss : 0.623144\n",
      "epoch 0 batch 236 g_loss : 0.446754\n",
      "epoch 0 batch 237 d_loss : 0.320970\n",
      "epoch 0 batch 237 g_loss : 0.440542\n",
      "epoch 0 batch 238 d_loss : 0.506315\n",
      "epoch 0 batch 238 g_loss : 0.394998\n",
      "epoch 0 batch 239 d_loss : 0.361237\n",
      "epoch 0 batch 239 g_loss : 0.539269\n",
      "epoch 0 batch 240 d_loss : 0.404202\n",
      "epoch 0 batch 240 g_loss : 0.450079\n",
      "epoch 0 batch 241 d_loss : 0.392211\n",
      "epoch 0 batch 241 g_loss : 0.478554\n",
      "epoch 0 batch 242 d_loss : 0.371884\n",
      "epoch 0 batch 242 g_loss : 0.442285\n",
      "epoch 0 batch 243 d_loss : 0.301428\n",
      "epoch 0 batch 243 g_loss : 0.463145\n",
      "epoch 0 batch 244 d_loss : 0.371473\n",
      "epoch 0 batch 244 g_loss : 0.447345\n",
      "epoch 0 batch 245 d_loss : 0.404787\n",
      "epoch 0 batch 245 g_loss : 0.533787\n",
      "epoch 0 batch 246 d_loss : 0.423643\n",
      "epoch 0 batch 246 g_loss : 0.414233\n",
      "epoch 0 batch 247 d_loss : 0.288804\n",
      "epoch 0 batch 247 g_loss : 0.418710\n",
      "epoch 0 batch 248 d_loss : 0.398762\n",
      "epoch 0 batch 248 g_loss : 0.538135\n",
      "epoch 0 batch 249 d_loss : 0.321824\n",
      "epoch 0 batch 249 g_loss : 0.396247\n",
      "epoch 0 batch 250 d_loss : 0.340260\n",
      "epoch 0 batch 250 g_loss : 0.430013\n",
      "epoch 0 batch 251 d_loss : 0.427538\n",
      "epoch 0 batch 251 g_loss : 0.507386\n",
      "epoch 0 batch 252 d_loss : 0.326211\n",
      "epoch 0 batch 252 g_loss : 0.374013\n",
      "epoch 0 batch 253 d_loss : 0.377313\n",
      "epoch 0 batch 253 g_loss : 0.538022\n",
      "epoch 0 batch 254 d_loss : 0.417581\n",
      "epoch 0 batch 254 g_loss : 0.520407\n",
      "epoch 0 batch 255 d_loss : 0.307317\n",
      "epoch 0 batch 255 g_loss : 0.440663\n",
      "epoch 0 batch 256 d_loss : 0.314264\n",
      "epoch 0 batch 256 g_loss : 0.430688\n",
      "epoch 0 batch 257 d_loss : 0.397156\n",
      "epoch 0 batch 257 g_loss : 0.468846\n",
      "epoch 0 batch 258 d_loss : 0.400388\n",
      "epoch 0 batch 258 g_loss : 0.398906\n",
      "epoch 0 batch 259 d_loss : 0.312084\n",
      "epoch 0 batch 259 g_loss : 0.416511\n",
      "epoch 0 batch 260 d_loss : 0.354189\n",
      "epoch 0 batch 260 g_loss : 0.427329\n",
      "epoch 0 batch 261 d_loss : 0.314671\n",
      "epoch 0 batch 261 g_loss : 0.461333\n",
      "epoch 0 batch 262 d_loss : 0.330871\n",
      "epoch 0 batch 262 g_loss : 0.443401\n",
      "epoch 0 batch 263 d_loss : 0.339156\n",
      "epoch 0 batch 263 g_loss : 0.465383\n",
      "epoch 0 batch 264 d_loss : 0.396243\n",
      "epoch 0 batch 264 g_loss : 0.478373\n",
      "epoch 0 batch 265 d_loss : 0.331726\n",
      "epoch 0 batch 265 g_loss : 0.485366\n",
      "epoch 0 batch 266 d_loss : 0.369909\n",
      "epoch 0 batch 266 g_loss : 0.470371\n",
      "epoch 0 batch 267 d_loss : 0.305226\n",
      "epoch 0 batch 267 g_loss : 0.549378\n",
      "epoch 0 batch 268 d_loss : 0.291933\n",
      "epoch 0 batch 268 g_loss : 0.478939\n",
      "epoch 0 batch 269 d_loss : 0.341677\n",
      "epoch 0 batch 269 g_loss : 0.451042\n",
      "epoch 0 batch 270 d_loss : 0.321714\n",
      "epoch 0 batch 270 g_loss : 0.474422\n",
      "epoch 0 batch 271 d_loss : 0.328312\n",
      "epoch 0 batch 271 g_loss : 0.385326\n",
      "epoch 0 batch 272 d_loss : 0.312193\n",
      "epoch 0 batch 272 g_loss : 0.478891\n",
      "epoch 0 batch 273 d_loss : 0.355837\n",
      "epoch 0 batch 273 g_loss : 0.420554\n",
      "epoch 0 batch 274 d_loss : 0.398679\n",
      "epoch 0 batch 274 g_loss : 0.441448\n",
      "epoch 0 batch 275 d_loss : 0.355631\n",
      "epoch 0 batch 275 g_loss : 0.407612\n",
      "epoch 0 batch 276 d_loss : 0.314149\n",
      "epoch 0 batch 276 g_loss : 0.437121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 277 d_loss : 0.319637\n",
      "epoch 0 batch 277 g_loss : 0.449203\n",
      "epoch 0 batch 278 d_loss : 0.331942\n",
      "epoch 0 batch 278 g_loss : 0.416254\n",
      "epoch 0 batch 279 d_loss : 0.356526\n",
      "epoch 0 batch 279 g_loss : 0.474385\n",
      "epoch 0 batch 280 d_loss : 0.361026\n",
      "epoch 0 batch 280 g_loss : 0.627418\n",
      "epoch 0 batch 281 d_loss : 0.367932\n",
      "epoch 0 batch 281 g_loss : 0.478966\n",
      "epoch 0 batch 282 d_loss : 0.366508\n",
      "epoch 0 batch 282 g_loss : 0.450413\n",
      "epoch 0 batch 283 d_loss : 0.324073\n",
      "epoch 0 batch 283 g_loss : 0.485460\n",
      "epoch 0 batch 284 d_loss : 0.361188\n",
      "epoch 0 batch 284 g_loss : 0.473356\n",
      "epoch 0 batch 285 d_loss : 0.319157\n",
      "epoch 0 batch 285 g_loss : 0.552455\n",
      "epoch 0 batch 286 d_loss : 0.271084\n",
      "epoch 0 batch 286 g_loss : 0.594261\n",
      "epoch 0 batch 287 d_loss : 0.327083\n",
      "epoch 0 batch 287 g_loss : 0.466235\n",
      "epoch 0 batch 288 d_loss : 0.317309\n",
      "epoch 0 batch 288 g_loss : 0.548202\n",
      "epoch 0 batch 289 d_loss : 0.411128\n",
      "epoch 0 batch 289 g_loss : 0.468857\n",
      "epoch 0 batch 290 d_loss : 0.325043\n",
      "epoch 0 batch 290 g_loss : 0.474230\n",
      "epoch 0 batch 291 d_loss : 0.316957\n",
      "epoch 0 batch 291 g_loss : 0.486277\n",
      "epoch 0 batch 292 d_loss : 0.397489\n",
      "epoch 0 batch 292 g_loss : 0.405767\n",
      "epoch 0 batch 293 d_loss : 0.334799\n",
      "epoch 0 batch 293 g_loss : 0.425201\n",
      "epoch 0 batch 294 d_loss : 0.338769\n",
      "epoch 0 batch 294 g_loss : 0.568757\n",
      "epoch 0 batch 295 d_loss : 0.355159\n",
      "epoch 0 batch 295 g_loss : 0.477540\n",
      "epoch 0 batch 296 d_loss : 0.375241\n",
      "epoch 0 batch 296 g_loss : 0.431036\n",
      "epoch 0 batch 297 d_loss : 0.344048\n",
      "epoch 0 batch 297 g_loss : 0.455405\n",
      "epoch 0 batch 298 d_loss : 0.388836\n",
      "epoch 0 batch 298 g_loss : 0.467224\n",
      "epoch 0 batch 299 d_loss : 0.303218\n",
      "epoch 0 batch 299 g_loss : 0.411889\n",
      "epoch 0 batch 300 d_loss : 0.333827\n",
      "epoch 0 batch 300 g_loss : 0.389254\n",
      "epoch 0 batch 301 d_loss : 0.338696\n",
      "epoch 0 batch 301 g_loss : 0.441315\n",
      "epoch 0 batch 302 d_loss : 0.366710\n",
      "epoch 0 batch 302 g_loss : 0.459103\n",
      "epoch 0 batch 303 d_loss : 0.376659\n",
      "epoch 0 batch 303 g_loss : 0.368191\n",
      "epoch 0 batch 304 d_loss : 0.320890\n",
      "epoch 0 batch 304 g_loss : 0.373572\n",
      "epoch 0 batch 305 d_loss : 0.321218\n",
      "epoch 0 batch 305 g_loss : 0.309700\n",
      "epoch 0 batch 306 d_loss : 0.313966\n",
      "epoch 0 batch 306 g_loss : 0.485897\n",
      "epoch 0 batch 307 d_loss : 0.408215\n",
      "epoch 0 batch 307 g_loss : 0.464716\n",
      "epoch 0 batch 308 d_loss : 0.309534\n",
      "epoch 0 batch 308 g_loss : 0.501150\n",
      "epoch 0 batch 309 d_loss : 0.372413\n",
      "epoch 0 batch 309 g_loss : 0.504043\n",
      "epoch 0 batch 310 d_loss : 0.309823\n",
      "epoch 0 batch 310 g_loss : 0.459161\n",
      "epoch 0 batch 311 d_loss : 0.280965\n",
      "epoch 0 batch 311 g_loss : 0.467908\n",
      "epoch 0 batch 312 d_loss : 0.354353\n",
      "epoch 0 batch 312 g_loss : 0.407529\n",
      "epoch 0 batch 313 d_loss : 0.354167\n",
      "epoch 0 batch 313 g_loss : 0.510343\n",
      "epoch 0 batch 314 d_loss : 0.337609\n",
      "epoch 0 batch 314 g_loss : 0.439167\n",
      "epoch 0 batch 315 d_loss : 0.597685\n",
      "epoch 0 batch 315 g_loss : 0.428249\n",
      "epoch 0 batch 316 d_loss : 0.308561\n",
      "epoch 0 batch 316 g_loss : 0.415458\n",
      "epoch 0 batch 317 d_loss : 0.361399\n",
      "epoch 0 batch 317 g_loss : 0.443430\n",
      "epoch 0 batch 318 d_loss : 0.405123\n",
      "epoch 0 batch 318 g_loss : 0.479385\n",
      "epoch 0 batch 319 d_loss : 0.358424\n",
      "epoch 0 batch 319 g_loss : 0.491455\n",
      "epoch 0 batch 320 d_loss : 0.333462\n",
      "epoch 0 batch 320 g_loss : 0.482251\n",
      "epoch 0 batch 321 d_loss : 0.321516\n",
      "epoch 0 batch 321 g_loss : 0.443107\n",
      "epoch 0 batch 322 d_loss : 0.318493\n",
      "epoch 0 batch 322 g_loss : 0.395452\n",
      "epoch 0 batch 323 d_loss : 0.315455\n",
      "epoch 0 batch 323 g_loss : 0.428867\n",
      "epoch 0 batch 324 d_loss : 0.301003\n",
      "epoch 0 batch 324 g_loss : 0.457407\n",
      "epoch 0 batch 325 d_loss : 0.316137\n",
      "epoch 0 batch 325 g_loss : 0.486361\n",
      "epoch 0 batch 326 d_loss : 0.346593\n",
      "epoch 0 batch 326 g_loss : 0.474365\n",
      "epoch 0 batch 327 d_loss : 0.327137\n",
      "epoch 0 batch 327 g_loss : 0.493387\n",
      "epoch 0 batch 328 d_loss : 0.328445\n",
      "epoch 0 batch 328 g_loss : 0.500680\n",
      "epoch 0 batch 329 d_loss : 0.336198\n",
      "epoch 0 batch 329 g_loss : 0.457813\n",
      "epoch 0 batch 330 d_loss : 0.342882\n",
      "epoch 0 batch 330 g_loss : 0.408474\n",
      "epoch 0 batch 331 d_loss : 0.382094\n",
      "epoch 0 batch 331 g_loss : 0.439406\n",
      "epoch 0 batch 332 d_loss : 0.330537\n",
      "epoch 0 batch 332 g_loss : 0.436938\n",
      "epoch 0 batch 333 d_loss : 0.317360\n",
      "epoch 0 batch 333 g_loss : 0.392450\n",
      "epoch 0 batch 334 d_loss : 0.332541\n",
      "epoch 0 batch 334 g_loss : 0.543927\n",
      "epoch 0 batch 335 d_loss : 0.397515\n",
      "epoch 0 batch 335 g_loss : 0.449286\n",
      "epoch 0 batch 336 d_loss : 0.311531\n",
      "epoch 0 batch 336 g_loss : 0.462191\n",
      "epoch 0 batch 337 d_loss : 0.385655\n",
      "epoch 0 batch 337 g_loss : 0.480018\n",
      "epoch 0 batch 338 d_loss : 0.326566\n",
      "epoch 0 batch 338 g_loss : 0.391194\n",
      "epoch 0 batch 339 d_loss : 0.333555\n",
      "epoch 0 batch 339 g_loss : 0.438187\n",
      "epoch 0 batch 340 d_loss : 0.315719\n",
      "epoch 0 batch 340 g_loss : 0.378325\n",
      "epoch 0 batch 341 d_loss : 0.403642\n",
      "epoch 0 batch 341 g_loss : 0.398527\n",
      "epoch 0 batch 342 d_loss : 0.331638\n",
      "epoch 0 batch 342 g_loss : 0.461697\n",
      "epoch 0 batch 343 d_loss : 0.350536\n",
      "epoch 0 batch 343 g_loss : 0.387137\n",
      "epoch 0 batch 344 d_loss : 0.302226\n",
      "epoch 0 batch 344 g_loss : 0.533760\n",
      "epoch 0 batch 345 d_loss : 0.402096\n",
      "epoch 0 batch 345 g_loss : 0.446082\n",
      "epoch 0 batch 346 d_loss : 0.326242\n",
      "epoch 0 batch 346 g_loss : 0.421258\n",
      "epoch 0 batch 347 d_loss : 0.356594\n",
      "epoch 0 batch 347 g_loss : 0.479208\n",
      "epoch 0 batch 348 d_loss : 0.349964\n",
      "epoch 0 batch 348 g_loss : 0.401443\n",
      "epoch 0 batch 349 d_loss : 0.319879\n",
      "epoch 0 batch 349 g_loss : 0.380034\n",
      "epoch 0 batch 350 d_loss : 0.382547\n",
      "epoch 0 batch 350 g_loss : 0.455783\n",
      "epoch 0 batch 351 d_loss : 0.322893\n",
      "epoch 0 batch 351 g_loss : 0.509458\n",
      "epoch 0 batch 352 d_loss : 0.353816\n",
      "epoch 0 batch 352 g_loss : 0.449076\n",
      "epoch 0 batch 353 d_loss : 0.318832\n",
      "epoch 0 batch 353 g_loss : 0.415165\n",
      "epoch 0 batch 354 d_loss : 0.322027\n",
      "epoch 0 batch 354 g_loss : 0.429920\n",
      "epoch 0 batch 355 d_loss : 0.372329\n",
      "epoch 0 batch 355 g_loss : 0.419395\n",
      "epoch 0 batch 356 d_loss : 0.327451\n",
      "epoch 0 batch 356 g_loss : 0.443972\n",
      "epoch 0 batch 357 d_loss : 0.347911\n",
      "epoch 0 batch 357 g_loss : 0.415020\n",
      "epoch 0 batch 358 d_loss : 0.292940\n",
      "epoch 0 batch 358 g_loss : 0.363148\n",
      "epoch 0 batch 359 d_loss : 0.381199\n",
      "epoch 0 batch 359 g_loss : 0.441743\n",
      "epoch 0 batch 360 d_loss : 0.371236\n",
      "epoch 0 batch 360 g_loss : 0.429272\n",
      "epoch 0 batch 361 d_loss : 0.336652\n",
      "epoch 0 batch 361 g_loss : 0.450131\n",
      "epoch 0 batch 362 d_loss : 0.392314\n",
      "epoch 0 batch 362 g_loss : 0.425173\n",
      "epoch 0 batch 363 d_loss : 0.334717\n",
      "epoch 0 batch 363 g_loss : 0.425867\n",
      "epoch 0 batch 364 d_loss : 0.336688\n",
      "epoch 0 batch 364 g_loss : 0.407335\n",
      "epoch 0 batch 365 d_loss : 0.345996\n",
      "epoch 0 batch 365 g_loss : 0.430294\n",
      "epoch 0 batch 366 d_loss : 0.383037\n",
      "epoch 0 batch 366 g_loss : 0.410308\n",
      "epoch 0 batch 367 d_loss : 0.378078\n",
      "epoch 0 batch 367 g_loss : 0.466429\n",
      "epoch 0 batch 368 d_loss : 0.343160\n",
      "epoch 0 batch 368 g_loss : 0.448492\n",
      "epoch 0 batch 369 d_loss : 0.330738\n",
      "epoch 0 batch 369 g_loss : 0.444254\n",
      "epoch 0 batch 370 d_loss : 0.337342\n",
      "epoch 0 batch 370 g_loss : 0.389343\n",
      "epoch 0 batch 371 d_loss : 0.374219\n",
      "epoch 0 batch 371 g_loss : 0.359776\n",
      "epoch 0 batch 372 d_loss : 0.332108\n",
      "epoch 0 batch 372 g_loss : 0.419385\n",
      "epoch 0 batch 373 d_loss : 0.367775\n",
      "epoch 0 batch 373 g_loss : 0.419133\n",
      "epoch 0 batch 374 d_loss : 0.331781\n",
      "epoch 0 batch 374 g_loss : 0.443122\n",
      "epoch 0 batch 375 d_loss : 0.343909\n",
      "epoch 0 batch 375 g_loss : 0.493818\n",
      "epoch 0 batch 376 d_loss : 0.366951\n",
      "epoch 0 batch 376 g_loss : 0.467855\n",
      "epoch 0 batch 377 d_loss : 0.319845\n",
      "epoch 0 batch 377 g_loss : 0.486117\n",
      "epoch 0 batch 378 d_loss : 0.332611\n",
      "epoch 0 batch 378 g_loss : 0.488036\n",
      "epoch 0 batch 379 d_loss : 0.394416\n",
      "epoch 0 batch 379 g_loss : 0.412034\n",
      "epoch 0 batch 380 d_loss : 0.364574\n",
      "epoch 0 batch 380 g_loss : 0.467674\n",
      "epoch 0 batch 381 d_loss : 0.362052\n",
      "epoch 0 batch 381 g_loss : 0.437850\n",
      "epoch 0 batch 382 d_loss : 0.331262\n",
      "epoch 0 batch 382 g_loss : 0.398143\n",
      "epoch 0 batch 383 d_loss : 0.348038\n",
      "epoch 0 batch 383 g_loss : 0.488211\n",
      "epoch 0 batch 384 d_loss : 0.348331\n",
      "epoch 0 batch 384 g_loss : 0.449561\n",
      "epoch 0 batch 385 d_loss : 0.344422\n",
      "epoch 0 batch 385 g_loss : 0.484155\n",
      "epoch 0 batch 386 d_loss : 0.347681\n",
      "epoch 0 batch 386 g_loss : 0.533822\n",
      "epoch 0 batch 387 d_loss : 0.314566\n",
      "epoch 0 batch 387 g_loss : 0.368631\n",
      "epoch 0 batch 388 d_loss : 0.353813\n",
      "epoch 0 batch 388 g_loss : 0.476781\n",
      "epoch 0 batch 389 d_loss : 0.367113\n",
      "epoch 0 batch 389 g_loss : 0.472470\n",
      "epoch 0 batch 390 d_loss : 0.344836\n",
      "epoch 0 batch 390 g_loss : 0.472908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 391 d_loss : 0.348143\n",
      "epoch 0 batch 391 g_loss : 0.391426\n",
      "epoch 0 batch 392 d_loss : 0.333663\n",
      "epoch 0 batch 392 g_loss : 0.388624\n",
      "epoch 0 batch 393 d_loss : 0.350288\n",
      "epoch 0 batch 393 g_loss : 0.442871\n",
      "epoch 0 batch 394 d_loss : 0.332546\n",
      "epoch 0 batch 394 g_loss : 0.489157\n",
      "epoch 0 batch 395 d_loss : 0.315403\n",
      "epoch 0 batch 395 g_loss : 0.435944\n",
      "epoch 0 batch 396 d_loss : 0.349906\n",
      "epoch 0 batch 396 g_loss : 0.465813\n",
      "epoch 0 batch 397 d_loss : 0.351265\n",
      "epoch 0 batch 397 g_loss : 0.402506\n",
      "epoch 0 batch 398 d_loss : 0.352218\n",
      "epoch 0 batch 398 g_loss : 0.424946\n",
      "epoch 0 batch 399 d_loss : 0.364568\n",
      "epoch 0 batch 399 g_loss : 0.468903\n",
      "epoch 0 batch 400 d_loss : 0.340590\n",
      "epoch 0 batch 400 g_loss : 0.404624\n",
      "epoch 0 batch 401 d_loss : 0.308184\n",
      "epoch 0 batch 401 g_loss : 0.420483\n",
      "epoch 0 batch 402 d_loss : 0.287643\n",
      "epoch 0 batch 402 g_loss : 0.452018\n",
      "epoch 0 batch 403 d_loss : 0.320998\n",
      "epoch 0 batch 403 g_loss : 0.475403\n",
      "epoch 0 batch 404 d_loss : 0.384224\n",
      "epoch 0 batch 404 g_loss : 0.395349\n",
      "epoch 0 batch 405 d_loss : 0.324488\n",
      "epoch 0 batch 405 g_loss : 0.476855\n",
      "epoch 0 batch 406 d_loss : 0.303266\n",
      "epoch 0 batch 406 g_loss : 0.498817\n",
      "epoch 0 batch 407 d_loss : 0.299024\n",
      "epoch 0 batch 407 g_loss : 0.387695\n",
      "epoch 0 batch 408 d_loss : 0.362493\n",
      "epoch 0 batch 408 g_loss : 0.471521\n",
      "epoch 0 batch 409 d_loss : 0.292979\n",
      "epoch 0 batch 409 g_loss : 0.507770\n",
      "epoch 0 batch 410 d_loss : 0.387516\n",
      "epoch 0 batch 410 g_loss : 0.381403\n",
      "epoch 0 batch 411 d_loss : 0.357128\n",
      "epoch 0 batch 411 g_loss : 0.576184\n",
      "epoch 0 batch 412 d_loss : 0.354787\n",
      "epoch 0 batch 412 g_loss : 0.436853\n",
      "epoch 0 batch 413 d_loss : 0.495614\n",
      "epoch 0 batch 413 g_loss : 0.678587\n",
      "epoch 0 batch 414 d_loss : 0.315683\n",
      "epoch 0 batch 414 g_loss : 0.496152\n",
      "epoch 0 batch 415 d_loss : 0.270941\n",
      "epoch 0 batch 415 g_loss : 0.462594\n",
      "epoch 0 batch 416 d_loss : 0.304246\n",
      "epoch 0 batch 416 g_loss : 0.456828\n",
      "epoch 0 batch 417 d_loss : 0.326814\n",
      "epoch 0 batch 417 g_loss : 0.515332\n",
      "epoch 0 batch 418 d_loss : 0.362056\n",
      "epoch 0 batch 418 g_loss : 0.434313\n",
      "epoch 0 batch 419 d_loss : 0.327961\n",
      "epoch 0 batch 419 g_loss : 0.444904\n",
      "epoch 0 batch 420 d_loss : 0.446360\n",
      "epoch 0 batch 420 g_loss : 0.392659\n",
      "epoch 0 batch 421 d_loss : 0.316935\n",
      "epoch 0 batch 421 g_loss : 0.425436\n",
      "epoch 0 batch 422 d_loss : 0.401802\n",
      "epoch 0 batch 422 g_loss : 0.417809\n",
      "epoch 0 batch 423 d_loss : 0.309845\n",
      "epoch 0 batch 423 g_loss : 0.445760\n",
      "epoch 0 batch 424 d_loss : 0.334548\n",
      "epoch 0 batch 424 g_loss : 0.457035\n",
      "epoch 0 batch 425 d_loss : 0.321031\n",
      "epoch 0 batch 425 g_loss : 0.338762\n",
      "epoch 0 batch 426 d_loss : 0.339225\n",
      "epoch 0 batch 426 g_loss : 0.405973\n",
      "epoch 0 batch 427 d_loss : 0.324276\n",
      "epoch 0 batch 427 g_loss : 0.552168\n",
      "epoch 0 batch 428 d_loss : 0.388839\n",
      "epoch 0 batch 428 g_loss : 0.419502\n",
      "epoch 0 batch 429 d_loss : 0.378190\n",
      "epoch 0 batch 429 g_loss : 0.444368\n",
      "epoch 0 batch 430 d_loss : 0.358211\n",
      "epoch 0 batch 430 g_loss : 0.372257\n",
      "epoch 0 batch 431 d_loss : 0.349394\n",
      "epoch 0 batch 431 g_loss : 0.416826\n",
      "epoch 0 batch 432 d_loss : 0.308836\n",
      "epoch 0 batch 432 g_loss : 0.429466\n",
      "epoch 0 batch 433 d_loss : 0.331018\n",
      "epoch 0 batch 433 g_loss : 0.414106\n",
      "epoch 0 batch 434 d_loss : 0.325841\n",
      "epoch 0 batch 434 g_loss : 0.489419\n",
      "epoch 0 batch 435 d_loss : 0.303791\n",
      "epoch 0 batch 435 g_loss : 0.439834\n",
      "epoch 0 batch 436 d_loss : 0.430068\n",
      "epoch 0 batch 436 g_loss : 0.415990\n",
      "epoch 0 batch 437 d_loss : 0.304806\n",
      "epoch 0 batch 437 g_loss : 0.453055\n",
      "epoch 0 batch 438 d_loss : 0.344177\n",
      "epoch 0 batch 438 g_loss : 0.402731\n",
      "epoch 0 batch 439 d_loss : 0.348332\n",
      "epoch 0 batch 439 g_loss : 0.523327\n",
      "epoch 0 batch 440 d_loss : 0.294810\n",
      "epoch 0 batch 440 g_loss : 0.439458\n",
      "epoch 0 batch 441 d_loss : 0.340957\n",
      "epoch 0 batch 441 g_loss : 0.475096\n",
      "epoch 0 batch 442 d_loss : 0.303300\n",
      "epoch 0 batch 442 g_loss : 0.440256\n",
      "epoch 0 batch 443 d_loss : 0.323486\n",
      "epoch 0 batch 443 g_loss : 0.453217\n",
      "epoch 0 batch 444 d_loss : 0.343591\n",
      "epoch 0 batch 444 g_loss : 0.437944\n",
      "epoch 0 batch 445 d_loss : 0.348007\n",
      "epoch 0 batch 445 g_loss : 0.431779\n",
      "epoch 0 batch 446 d_loss : 0.359001\n",
      "epoch 0 batch 446 g_loss : 0.469067\n",
      "epoch 0 batch 447 d_loss : 0.331210\n",
      "epoch 0 batch 447 g_loss : 0.419191\n",
      "epoch 0 batch 448 d_loss : 0.318101\n",
      "epoch 0 batch 448 g_loss : 0.429757\n",
      "epoch 0 batch 449 d_loss : 0.295435\n",
      "epoch 0 batch 449 g_loss : 0.445681\n",
      "epoch 0 batch 450 d_loss : 0.339878\n",
      "epoch 0 batch 450 g_loss : 0.464195\n",
      "epoch 0 batch 451 d_loss : 0.338025\n",
      "epoch 0 batch 451 g_loss : 0.369632\n",
      "epoch 0 batch 452 d_loss : 0.358613\n",
      "epoch 0 batch 452 g_loss : 0.436320\n",
      "epoch 0 batch 453 d_loss : 0.390568\n",
      "epoch 0 batch 453 g_loss : 0.400194\n",
      "epoch 0 batch 454 d_loss : 0.271258\n",
      "epoch 0 batch 454 g_loss : 0.409806\n",
      "epoch 0 batch 455 d_loss : 0.307431\n",
      "epoch 0 batch 455 g_loss : 0.460138\n",
      "epoch 0 batch 456 d_loss : 0.343368\n",
      "epoch 0 batch 456 g_loss : 0.451746\n",
      "epoch 0 batch 457 d_loss : 0.345485\n",
      "epoch 0 batch 457 g_loss : 0.370049\n",
      "epoch 0 batch 458 d_loss : 0.366803\n",
      "epoch 0 batch 458 g_loss : 0.434836\n",
      "epoch 0 batch 459 d_loss : 0.362393\n",
      "epoch 0 batch 459 g_loss : 0.456574\n",
      "epoch 0 batch 460 d_loss : 0.381424\n",
      "epoch 0 batch 460 g_loss : 0.400954\n",
      "epoch 0 batch 461 d_loss : 0.337921\n",
      "epoch 0 batch 461 g_loss : 0.431317\n",
      "epoch 0 batch 462 d_loss : 0.296541\n",
      "epoch 0 batch 462 g_loss : 0.437856\n",
      "epoch 0 batch 463 d_loss : 0.341404\n",
      "epoch 0 batch 463 g_loss : 0.441183\n",
      "epoch 0 batch 464 d_loss : 0.341997\n",
      "epoch 0 batch 464 g_loss : 0.422749\n",
      "epoch 0 batch 465 d_loss : 0.320983\n",
      "epoch 0 batch 465 g_loss : 0.414098\n",
      "epoch 0 batch 466 d_loss : 0.352009\n",
      "epoch 0 batch 466 g_loss : 0.440659\n",
      "epoch 0 batch 467 d_loss : 0.311027\n",
      "epoch 0 batch 467 g_loss : 0.385540\n",
      "epoch 0 batch 468 d_loss : 0.355932\n",
      "epoch 0 batch 468 g_loss : 0.451231\n",
      "epoch 0 batch 469 d_loss : 0.327548\n",
      "epoch 0 batch 469 g_loss : 0.384598\n",
      "epoch 0 batch 470 d_loss : 0.323871\n",
      "epoch 0 batch 470 g_loss : 0.424779\n",
      "epoch 0 batch 471 d_loss : 0.362201\n",
      "epoch 0 batch 471 g_loss : 0.397318\n",
      "epoch 0 batch 472 d_loss : 0.337083\n",
      "epoch 0 batch 472 g_loss : 0.460026\n",
      "epoch 0 batch 473 d_loss : 0.372758\n",
      "epoch 0 batch 473 g_loss : 0.419817\n",
      "epoch 0 batch 474 d_loss : 0.337357\n",
      "epoch 0 batch 474 g_loss : 0.399664\n",
      "epoch 0 batch 475 d_loss : 0.309741\n",
      "epoch 0 batch 475 g_loss : 0.431031\n",
      "epoch 0 batch 476 d_loss : 0.288224\n",
      "epoch 0 batch 476 g_loss : 0.469954\n",
      "epoch 0 batch 477 d_loss : 0.339183\n",
      "epoch 0 batch 477 g_loss : 0.402665\n",
      "epoch 0 batch 478 d_loss : 0.337519\n",
      "epoch 0 batch 478 g_loss : 0.429379\n",
      "epoch 0 batch 479 d_loss : 0.285624\n",
      "epoch 0 batch 479 g_loss : 0.420213\n",
      "epoch 0 batch 480 d_loss : 0.410606\n",
      "epoch 0 batch 480 g_loss : 0.409575\n",
      "epoch 0 batch 481 d_loss : 0.341885\n",
      "epoch 0 batch 481 g_loss : 0.427817\n",
      "epoch 0 batch 482 d_loss : 0.339901\n",
      "epoch 0 batch 482 g_loss : 0.433458\n",
      "epoch 0 batch 483 d_loss : 0.313081\n",
      "epoch 0 batch 483 g_loss : 0.456665\n",
      "epoch 0 batch 484 d_loss : 0.368492\n",
      "epoch 0 batch 484 g_loss : 0.421868\n",
      "epoch 0 batch 485 d_loss : 0.316128\n",
      "epoch 0 batch 485 g_loss : 0.501445\n",
      "epoch 0 batch 486 d_loss : 0.347188\n",
      "epoch 0 batch 486 g_loss : 0.518226\n",
      "epoch 0 batch 487 d_loss : 0.296885\n",
      "epoch 0 batch 487 g_loss : 0.471486\n",
      "epoch 0 batch 488 d_loss : 0.369362\n",
      "epoch 0 batch 488 g_loss : 0.376124\n",
      "epoch 0 batch 489 d_loss : 0.380758\n",
      "epoch 0 batch 489 g_loss : 0.452357\n",
      "epoch 0 batch 490 d_loss : 0.356022\n",
      "epoch 0 batch 490 g_loss : 0.405921\n",
      "epoch 0 batch 491 d_loss : 0.339290\n",
      "epoch 0 batch 491 g_loss : 0.378118\n",
      "epoch 0 batch 492 d_loss : 0.302564\n",
      "epoch 0 batch 492 g_loss : 0.434793\n",
      "epoch 0 batch 493 d_loss : 0.317450\n",
      "epoch 0 batch 493 g_loss : 0.394548\n",
      "epoch 0 batch 494 d_loss : 0.362820\n",
      "epoch 0 batch 494 g_loss : 0.436143\n",
      "epoch 0 batch 495 d_loss : 0.399430\n",
      "epoch 0 batch 495 g_loss : 0.411878\n",
      "epoch 0 batch 496 d_loss : 0.349460\n",
      "epoch 0 batch 496 g_loss : 0.444756\n",
      "epoch 0 batch 497 d_loss : 0.305793\n",
      "epoch 0 batch 497 g_loss : 0.457713\n",
      "epoch 0 batch 498 d_loss : 0.381787\n",
      "epoch 0 batch 498 g_loss : 0.440999\n",
      "epoch 0 batch 499 d_loss : 0.373679\n",
      "epoch 0 batch 499 g_loss : 0.458310\n",
      "epoch 0 batch 500 d_loss : 0.279650\n",
      "epoch 0 batch 500 g_loss : 0.430921\n",
      "epoch 0 batch 501 d_loss : 0.349690\n",
      "epoch 0 batch 501 g_loss : 0.457304\n",
      "epoch 0 batch 502 d_loss : 0.330362\n",
      "epoch 0 batch 502 g_loss : 0.430462\n",
      "epoch 0 batch 503 d_loss : 0.372303\n",
      "epoch 0 batch 503 g_loss : 0.457618\n",
      "epoch 0 batch 504 d_loss : 0.318654\n",
      "epoch 0 batch 504 g_loss : 0.428161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 505 d_loss : 0.307939\n",
      "epoch 0 batch 505 g_loss : 0.415535\n",
      "epoch 0 batch 506 d_loss : 0.310187\n",
      "epoch 0 batch 506 g_loss : 0.477607\n",
      "epoch 0 batch 507 d_loss : 0.349847\n",
      "epoch 0 batch 507 g_loss : 0.416318\n",
      "epoch 0 batch 508 d_loss : 0.326241\n",
      "epoch 0 batch 508 g_loss : 0.436590\n",
      "epoch 0 batch 509 d_loss : 0.341144\n",
      "epoch 0 batch 509 g_loss : 0.494951\n",
      "epoch 0 batch 510 d_loss : 0.355773\n",
      "epoch 0 batch 510 g_loss : 0.444476\n",
      "epoch 0 batch 511 d_loss : 0.330859\n",
      "epoch 0 batch 511 g_loss : 0.408109\n",
      "epoch 0 batch 512 d_loss : 0.353938\n",
      "epoch 0 batch 512 g_loss : 0.409421\n",
      "epoch 0 batch 513 d_loss : 0.370314\n",
      "epoch 0 batch 513 g_loss : 0.430715\n",
      "epoch 0 batch 514 d_loss : 0.310500\n",
      "epoch 0 batch 514 g_loss : 0.437720\n",
      "epoch 0 batch 515 d_loss : 0.363692\n",
      "epoch 0 batch 515 g_loss : 0.461375\n",
      "epoch 0 batch 516 d_loss : 0.379626\n",
      "epoch 0 batch 516 g_loss : 0.479671\n",
      "epoch 0 batch 517 d_loss : 0.353021\n",
      "epoch 0 batch 517 g_loss : 0.408762\n",
      "epoch 0 batch 518 d_loss : 0.305863\n",
      "epoch 0 batch 518 g_loss : 0.418925\n",
      "epoch 0 batch 519 d_loss : 0.323356\n",
      "epoch 0 batch 519 g_loss : 0.453380\n",
      "epoch 0 batch 520 d_loss : 0.339089\n",
      "epoch 0 batch 520 g_loss : 0.464814\n",
      "epoch 0 batch 521 d_loss : 0.324354\n",
      "epoch 0 batch 521 g_loss : 0.489411\n",
      "epoch 0 batch 522 d_loss : 0.317264\n",
      "epoch 0 batch 522 g_loss : 0.488238\n",
      "epoch 0 batch 523 d_loss : 0.301375\n",
      "epoch 0 batch 523 g_loss : 0.478841\n",
      "epoch 0 batch 524 d_loss : 0.348338\n",
      "epoch 0 batch 524 g_loss : 0.451972\n",
      "epoch 0 batch 525 d_loss : 0.322237\n",
      "epoch 0 batch 525 g_loss : 0.453857\n",
      "epoch 0 batch 526 d_loss : 0.347132\n",
      "epoch 0 batch 526 g_loss : 0.434442\n",
      "epoch 0 batch 527 d_loss : 0.429567\n",
      "epoch 0 batch 527 g_loss : 0.484377\n",
      "epoch 0 batch 528 d_loss : 0.331022\n",
      "epoch 0 batch 528 g_loss : 0.472410\n",
      "epoch 0 batch 529 d_loss : 0.346005\n",
      "epoch 0 batch 529 g_loss : 0.445510\n",
      "epoch 0 batch 530 d_loss : 0.310568\n",
      "epoch 0 batch 530 g_loss : 0.413654\n",
      "epoch 0 batch 531 d_loss : 0.310484\n",
      "epoch 0 batch 531 g_loss : 0.453270\n",
      "epoch 0 batch 532 d_loss : 0.360285\n",
      "epoch 0 batch 532 g_loss : 0.452117\n",
      "epoch 0 batch 533 d_loss : 0.342835\n",
      "epoch 0 batch 533 g_loss : 0.408287\n",
      "epoch 0 batch 534 d_loss : 0.358663\n",
      "epoch 0 batch 534 g_loss : 0.408288\n",
      "epoch 0 batch 535 d_loss : 0.362302\n",
      "epoch 0 batch 535 g_loss : 0.402390\n",
      "epoch 0 batch 536 d_loss : 0.347289\n",
      "epoch 0 batch 536 g_loss : 0.485309\n",
      "epoch 0 batch 537 d_loss : 0.331279\n",
      "epoch 0 batch 537 g_loss : 0.454165\n",
      "epoch 0 batch 538 d_loss : 0.304005\n",
      "epoch 0 batch 538 g_loss : 0.442627\n",
      "epoch 0 batch 539 d_loss : 0.381906\n",
      "epoch 0 batch 539 g_loss : 0.457271\n",
      "epoch 0 batch 540 d_loss : 0.291038\n",
      "epoch 0 batch 540 g_loss : 0.455677\n",
      "epoch 0 batch 541 d_loss : 0.300910\n",
      "epoch 0 batch 541 g_loss : 0.447255\n",
      "epoch 0 batch 542 d_loss : 0.279558\n",
      "epoch 0 batch 542 g_loss : 0.407568\n",
      "epoch 0 batch 543 d_loss : 0.364968\n",
      "epoch 0 batch 543 g_loss : 0.434120\n",
      "epoch 0 batch 544 d_loss : 0.340136\n",
      "epoch 0 batch 544 g_loss : 0.498962\n",
      "epoch 0 batch 545 d_loss : 0.356847\n",
      "epoch 0 batch 545 g_loss : 0.465069\n",
      "epoch 0 batch 546 d_loss : 0.355085\n",
      "epoch 0 batch 546 g_loss : 0.426359\n",
      "epoch 0 batch 547 d_loss : 0.347380\n",
      "epoch 0 batch 547 g_loss : 0.468871\n",
      "epoch 0 batch 548 d_loss : 0.342039\n",
      "epoch 0 batch 548 g_loss : 0.445216\n",
      "epoch 0 batch 549 d_loss : 0.326156\n",
      "epoch 0 batch 549 g_loss : 0.480347\n",
      "epoch 0 batch 550 d_loss : 0.332368\n",
      "epoch 0 batch 550 g_loss : 0.376949\n",
      "epoch 0 batch 551 d_loss : 0.347881\n",
      "epoch 0 batch 551 g_loss : 0.327003\n",
      "epoch 0 batch 552 d_loss : 0.344330\n",
      "epoch 0 batch 552 g_loss : 0.521930\n",
      "epoch 0 batch 553 d_loss : 0.339653\n",
      "epoch 0 batch 553 g_loss : 0.453170\n",
      "epoch 0 batch 554 d_loss : 0.332978\n",
      "epoch 0 batch 554 g_loss : 0.460966\n",
      "epoch 0 batch 555 d_loss : 0.406661\n",
      "epoch 0 batch 555 g_loss : 0.405569\n",
      "epoch 0 batch 556 d_loss : 0.301145\n",
      "epoch 0 batch 556 g_loss : 0.420035\n",
      "epoch 0 batch 557 d_loss : 0.367621\n",
      "epoch 0 batch 557 g_loss : 0.460229\n",
      "epoch 0 batch 558 d_loss : 0.356679\n",
      "epoch 0 batch 558 g_loss : 0.463978\n",
      "epoch 0 batch 559 d_loss : 0.356308\n",
      "epoch 0 batch 559 g_loss : 0.534003\n",
      "epoch 0 batch 560 d_loss : 0.354646\n",
      "epoch 0 batch 560 g_loss : 0.430478\n",
      "epoch 0 batch 561 d_loss : 0.310154\n",
      "epoch 0 batch 561 g_loss : 0.517475\n",
      "epoch 0 batch 562 d_loss : 0.362292\n",
      "epoch 0 batch 562 g_loss : 0.425645\n",
      "epoch 0 batch 563 d_loss : 0.309242\n",
      "epoch 0 batch 563 g_loss : 0.418331\n",
      "epoch 0 batch 564 d_loss : 0.362097\n",
      "epoch 0 batch 564 g_loss : 0.486525\n",
      "epoch 0 batch 565 d_loss : 0.368767\n",
      "epoch 0 batch 565 g_loss : 0.403318\n",
      "epoch 0 batch 566 d_loss : 0.334809\n",
      "epoch 0 batch 566 g_loss : 0.457666\n",
      "epoch 0 batch 567 d_loss : 0.388820\n",
      "epoch 0 batch 567 g_loss : 0.447971\n",
      "epoch 0 batch 568 d_loss : 0.317645\n",
      "epoch 0 batch 568 g_loss : 0.436799\n",
      "epoch 0 batch 569 d_loss : 0.365827\n",
      "epoch 0 batch 569 g_loss : 0.381006\n",
      "epoch 0 batch 570 d_loss : 0.333521\n",
      "epoch 0 batch 570 g_loss : 0.451354\n",
      "epoch 0 batch 571 d_loss : 0.340934\n",
      "epoch 0 batch 571 g_loss : 0.445265\n",
      "epoch 0 batch 572 d_loss : 0.386324\n",
      "epoch 0 batch 572 g_loss : 0.467107\n",
      "epoch 0 batch 573 d_loss : 0.345658\n",
      "epoch 0 batch 573 g_loss : 0.455909\n",
      "epoch 0 batch 574 d_loss : 0.356981\n",
      "epoch 0 batch 574 g_loss : 0.440691\n",
      "epoch 0 batch 575 d_loss : 0.332810\n",
      "epoch 0 batch 575 g_loss : 0.444854\n",
      "epoch 0 batch 576 d_loss : 0.345167\n",
      "epoch 0 batch 576 g_loss : 0.449380\n",
      "epoch 0 batch 577 d_loss : 0.320031\n",
      "epoch 0 batch 577 g_loss : 0.430770\n",
      "epoch 0 batch 578 d_loss : 0.349236\n",
      "epoch 0 batch 578 g_loss : 0.445725\n",
      "epoch 0 batch 579 d_loss : 0.330918\n",
      "epoch 0 batch 579 g_loss : 0.437242\n",
      "epoch 0 batch 580 d_loss : 0.363361\n",
      "epoch 0 batch 580 g_loss : 0.422150\n",
      "epoch 0 batch 581 d_loss : 0.331372\n",
      "epoch 0 batch 581 g_loss : 0.424467\n",
      "epoch 0 batch 582 d_loss : 0.339846\n",
      "epoch 0 batch 582 g_loss : 0.430870\n",
      "epoch 0 batch 583 d_loss : 0.354933\n",
      "epoch 0 batch 583 g_loss : 0.471145\n",
      "epoch 0 batch 584 d_loss : 0.318574\n",
      "epoch 0 batch 584 g_loss : 0.406306\n",
      "epoch 0 batch 585 d_loss : 0.286880\n",
      "epoch 0 batch 585 g_loss : 0.406790\n",
      "epoch 0 batch 586 d_loss : 0.320442\n",
      "epoch 0 batch 586 g_loss : 0.418629\n",
      "epoch 0 batch 587 d_loss : 0.390631\n",
      "epoch 0 batch 587 g_loss : 0.455396\n",
      "epoch 0 batch 588 d_loss : 0.282414\n",
      "epoch 0 batch 588 g_loss : 0.388713\n",
      "epoch 0 batch 589 d_loss : 0.359429\n",
      "epoch 0 batch 589 g_loss : 0.429959\n",
      "epoch 0 batch 590 d_loss : 0.329529\n",
      "epoch 0 batch 590 g_loss : 0.417304\n",
      "epoch 0 batch 591 d_loss : 0.376083\n",
      "epoch 0 batch 591 g_loss : 0.397672\n",
      "epoch 0 batch 592 d_loss : 0.304193\n",
      "epoch 0 batch 592 g_loss : 0.347494\n",
      "epoch 0 batch 593 d_loss : 0.371917\n",
      "epoch 0 batch 593 g_loss : 0.406249\n",
      "epoch 0 batch 594 d_loss : 0.312165\n",
      "epoch 0 batch 594 g_loss : 0.421572\n",
      "epoch 0 batch 595 d_loss : 0.315876\n",
      "epoch 0 batch 595 g_loss : 0.461577\n",
      "epoch 0 batch 596 d_loss : 0.339040\n",
      "epoch 0 batch 596 g_loss : 0.418140\n",
      "epoch 0 batch 597 d_loss : 0.317117\n",
      "epoch 0 batch 597 g_loss : 0.467595\n",
      "epoch 0 batch 598 d_loss : 0.325358\n",
      "epoch 0 batch 598 g_loss : 0.476690\n",
      "epoch 0 batch 599 d_loss : 0.348990\n",
      "epoch 0 batch 599 g_loss : 0.402334\n"
     ]
    }
   ],
   "source": [
    "train_another(1000, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_moment = datetime.now()\n",
    "\n",
    "day, month = str(current_moment.day), str(current_moment.month)\n",
    "hour, minute = str(current_moment.hour), str(current_moment.minute)\n",
    "\n",
    "with open(os.getcwd() + '/Changes.txt', 'a') as f:\n",
    "    clock =  (day + '.' + month + '    ' + hour + ':' + minute)\n",
    "    f.write(clock + '...........g_optim -> 0.0003, d_optim->0.0004' + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
