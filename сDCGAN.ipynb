{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\Anaconda1\\envs\\NN\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "from scipy.misc.pilutil import imresize, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout, Input\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import initializers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 16 * 8, input_dim = latent_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((8, 8, 256)))\n",
    "        \n",
    "        model.add(Conv2DTranspose(512, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(512, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(256, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(128, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(64, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(32, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(16, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(8, filter_size_g, strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Conv2DTranspose(img_channels, filter_size_g, strides=(1,1), padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size=filter_size_d, strides = (2,2), input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256,  kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=filter_size_d, strides = (2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = g(noise)\n",
    "    d.trainable = False\n",
    "    #d_label.trainable = False\n",
    "    valid = d(img)\n",
    "    \n",
    "    \n",
    "    return Model(noise, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(epoch, gen):\n",
    "        count = 5\n",
    "        noise = np.random.uniform(-1, 1, size=(count, latent_dim))\n",
    "        gen_imgs = gen.predict(noise)\n",
    "\n",
    "        gen_imgs = 127.5 * gen_imgs + 127.5\n",
    "        \n",
    "        if gen_imgs.shape[3] == 1:\n",
    "            gen_imgs = gen_imgs[:,:,:,0]\n",
    "        \n",
    "        for i in range(count):\n",
    "            cv2.imwrite(os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, i), gen_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(indices, data, batch_size):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    for i in range(batch_size):\n",
    "        if color_mode == 'grayscale':\n",
    "            temp_img = cv2.imread(data[indices[i]], 0)\n",
    "            X_train[i,:,:,0] = temp_img\n",
    "        else:\n",
    "            temp_img = cv2.imread(data[indices[i]])\n",
    "            X_train[i] = temp_img\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_classes(batch_size, data):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size)\n",
    "    choice_arr = np.random.randint(0, len(data), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        rand_number = np.random.randint(0, len(data[choice_arr[i]]))\n",
    "        temp_img = cv2.imread(data[choice_arr[i]][rand_number])\n",
    "        \n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]\n",
    "    \n",
    "\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_one_class(batch_size, data, class_target):\n",
    "    X_train = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    y_labels = np.zeros(batch_size) + class_target\n",
    "    '''choice_arr = np.random.randint(0, len(data[class_target]), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(data[class_target][choice_arr[i]])\n",
    "\n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = choice_arr[i]'''\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        temp_img = cv2.imread(os.getcwd() + '/new256_images/abstraktnyy-ekspressionizm/303.png')\n",
    "        \n",
    "        X_train[i] = temp_img\n",
    "        y_labels[i] = 0\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    return X_train, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], img_channels),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, :,]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    styles_folder = os.listdir(path=os.getcwd() + \"\\\\new256_images\\\\\")\n",
    "    num_styles = len(styles_folder)\n",
    "    data = []\n",
    "    for i in range(num_styles):\n",
    "        data.append(glob.glob(os.getcwd() + '\\\\new256_images\\\\' + styles_folder[i] + '\\\\*'))\n",
    "    return data, num_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_another(epochs = 100, BATCH_SIZE = 4):\n",
    "\n",
    "    data, num_styles = get_data()\n",
    "    \n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    discriminator.compile(loss=losses[0], optimizer=d_optim)\n",
    "    #d_label.compile(loss=losses[1], optimizer=d_optim)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    dcgan = generator_containing_discriminator(generator, discriminator)\n",
    "    \n",
    "    \n",
    "    dcgan.compile(loss=losses[0], optimizer=g_optim)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    #d_label.trainable = True\n",
    "    \n",
    "    \n",
    "    '''(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))'''\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for index in range(int(15000/BATCH_SIZE)):\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "                \n",
    "            #real_images, real_labels = get_images_classes(batch_size=BATCH_SIZE, data = data)\n",
    "            \n",
    "            label = index % num_styles\n",
    "            \n",
    "            real_images, real_labels = get_images_one_class(BATCH_SIZE, data, label)\n",
    "            \n",
    "            real_images += np.random.normal(size = img_shape, scale= 0.1)\n",
    "            \n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            if index % 2 == 0:\n",
    "                X = real_images\n",
    "                real_labels = real_labels - 0.1 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + label, num_styles)\n",
    "                y = 0.8 + np.random.rand(BATCH_SIZE)*0.2\n",
    "                \n",
    "                d_loss = []\n",
    "                d_loss.append(discriminator.train_on_batch(X, y))\n",
    "                #discriminator.trainable = False\n",
    "                #d_loss.append(d_label.train_on_batch(X, y_classif))\n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss[0]))\n",
    "            else:\n",
    "                X = generated_images\n",
    "                y = np.random.rand(BATCH_SIZE) * 0.2\n",
    "                d_loss = discriminator.train_on_batch(X, y)\n",
    "                print(\"epoch %d batch %d d_loss : %f\" % (epoch, index, d_loss))\n",
    "            \n",
    "            \n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, latent_dim))\n",
    "            \n",
    "            discriminator.trainable = False\n",
    "            #d_label.trainable = False\n",
    "            \n",
    "            y_classif = keras.utils.to_categorical(np.zeros(BATCH_SIZE) + 0.5, num_styles)\n",
    "            y = np.random.rand(BATCH_SIZE) * 0.3\n",
    "            \n",
    "            g_loss = dcgan.train_on_batch(noise, y)\n",
    "            \n",
    "            #d_label.trainable = True\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            print(\"epoch %d batch %d g_loss : %f\" % (epoch, index, g_loss))\n",
    "            \n",
    "            if index % 50 == 0:\n",
    "                        image = combine_images(generated_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d.png' % (epoch, index), image)\n",
    "                        image = combine_images(real_images)\n",
    "                        image = image*127.5+127.5\n",
    "                        cv2.imwrite(\n",
    "                            os.getcwd() + '\\\\generated\\\\epoch%d_%d_data.png' % (epoch, index), image)\n",
    "                        \n",
    "        if epoch % 5 == 0:\n",
    "            \n",
    "            \n",
    "            date_today = date.today()\n",
    "            \n",
    "            \n",
    "            \n",
    "            month, day = date_today.month, date_today.day\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            d_json = discriminator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d dis_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            '''# Генерируем описание модели в формате json\n",
    "            d_l_json = d_label.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d dis_label_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(d_l_json)\n",
    "            json_file.close()'''\n",
    "            \n",
    "            # Генерируем описание модели в формате json\n",
    "            gen_json = generator.to_json()\n",
    "            # Записываем модель в файл\n",
    "            json_file = open(os.getcwd() + \"%d.%d gen_model.json\" % (day, month), \"w\")\n",
    "            json_file.write(gen_json)\n",
    "            json_file.close()\n",
    "            \n",
    "            discriminator.save_weights(os.getcwd() + '%d.%d dis_weights.h5' % (day, month))\n",
    "            #d_label.save_weights(os.getcwd() + '%d.%d dis_label_weights.h5' % (day, month))\n",
    "            generator.save_weights(os.getcwd() + '%d.%d gen_weights.h5' % (day, month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "img_channels = 3\n",
    "img_shape = (img_rows, img_cols, img_channels)\n",
    "latent_dim = 100\n",
    "filter_size_g = (5,5)\n",
    "filter_size_d = (5,5)\n",
    "d_strides = (2,2)\n",
    "\n",
    "color_mode = 'rgb'\n",
    "\n",
    "losses = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "\n",
    "\n",
    "#g_optim = SGD(lr = 0.001, momentum=0.9, nesterov=True)\n",
    "#d_optim = SGD(lr = 0.00025, momentum=0.9, nesterov=True)\n",
    "g_optim = Adam(0.0002, beta_2 = 0.5)\n",
    "d_optim = Adam(0.0002, beta_2 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 8, 8, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 16, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 64, 64, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 128, 128, 16)      12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 256, 256, 8)       3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256, 256, 8)       32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 256, 256, 3)       603       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 15,926,963\n",
      "Trainable params: 15,891,139\n",
      "Non-trainable params: 35,824\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,430,657\n",
      "Trainable params: 17,426,817\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "epoch 0 batch 0 d_loss : 0.682740\n",
      "epoch 0 batch 0 g_loss : 4.420318\n",
      "epoch 0 batch 1 d_loss : 4.373912\n",
      "epoch 0 batch 1 g_loss : 1.516558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 2 d_loss : 1.581627\n",
      "epoch 0 batch 2 g_loss : 0.421538\n",
      "epoch 0 batch 3 d_loss : 0.412669\n",
      "epoch 0 batch 3 g_loss : 0.918834\n",
      "epoch 0 batch 4 d_loss : 0.931082\n",
      "epoch 0 batch 4 g_loss : 1.284591\n",
      "epoch 0 batch 5 d_loss : 0.875572\n",
      "epoch 0 batch 5 g_loss : 1.106225\n",
      "epoch 0 batch 6 d_loss : 2.418252\n",
      "epoch 0 batch 6 g_loss : 1.749577\n",
      "epoch 0 batch 7 d_loss : 0.935993\n",
      "epoch 0 batch 7 g_loss : 1.521374\n",
      "epoch 0 batch 8 d_loss : 0.632271\n",
      "epoch 0 batch 8 g_loss : 0.788820\n",
      "epoch 0 batch 9 d_loss : 0.491100\n",
      "epoch 0 batch 9 g_loss : 0.674360\n",
      "epoch 0 batch 10 d_loss : 1.509620\n",
      "epoch 0 batch 10 g_loss : 1.838554\n",
      "epoch 0 batch 11 d_loss : 2.367131\n",
      "epoch 0 batch 11 g_loss : 1.214953\n",
      "epoch 0 batch 12 d_loss : 1.590645\n",
      "epoch 0 batch 12 g_loss : 0.568986\n",
      "epoch 0 batch 13 d_loss : 0.469259\n",
      "epoch 0 batch 13 g_loss : 0.861941\n",
      "epoch 0 batch 14 d_loss : 1.282153\n",
      "epoch 0 batch 14 g_loss : 1.654452\n",
      "epoch 0 batch 15 d_loss : 1.000771\n",
      "epoch 0 batch 15 g_loss : 1.873090\n",
      "epoch 0 batch 16 d_loss : 1.248353\n",
      "epoch 0 batch 16 g_loss : 1.815389\n",
      "epoch 0 batch 17 d_loss : 1.043282\n",
      "epoch 0 batch 17 g_loss : 2.450204\n",
      "epoch 0 batch 18 d_loss : 0.701151\n",
      "epoch 0 batch 18 g_loss : 2.138888\n",
      "epoch 0 batch 19 d_loss : 1.336858\n",
      "epoch 0 batch 19 g_loss : 1.711959\n",
      "epoch 0 batch 20 d_loss : 0.671073\n",
      "epoch 0 batch 20 g_loss : 1.152466\n",
      "epoch 0 batch 21 d_loss : 1.123423\n",
      "epoch 0 batch 21 g_loss : 0.916221\n",
      "epoch 0 batch 22 d_loss : 0.720766\n",
      "epoch 0 batch 22 g_loss : 0.867292\n",
      "epoch 0 batch 23 d_loss : 0.446117\n",
      "epoch 0 batch 23 g_loss : 0.719230\n",
      "epoch 0 batch 24 d_loss : 0.652315\n",
      "epoch 0 batch 24 g_loss : 0.836537\n",
      "epoch 0 batch 25 d_loss : 0.761042\n",
      "epoch 0 batch 25 g_loss : 0.617305\n",
      "epoch 0 batch 26 d_loss : 0.554143\n",
      "epoch 0 batch 26 g_loss : 0.744422\n",
      "epoch 0 batch 27 d_loss : 0.617263\n",
      "epoch 0 batch 27 g_loss : 0.775917\n",
      "epoch 0 batch 28 d_loss : 0.521073\n",
      "epoch 0 batch 28 g_loss : 1.069453\n",
      "epoch 0 batch 29 d_loss : 0.647381\n",
      "epoch 0 batch 29 g_loss : 1.337702\n",
      "epoch 0 batch 30 d_loss : 0.573743\n",
      "epoch 0 batch 30 g_loss : 1.328301\n",
      "epoch 0 batch 31 d_loss : 0.689930\n",
      "epoch 0 batch 31 g_loss : 1.284320\n",
      "epoch 0 batch 32 d_loss : 0.588238\n",
      "epoch 0 batch 32 g_loss : 0.787125\n",
      "epoch 0 batch 33 d_loss : 0.619851\n",
      "epoch 0 batch 33 g_loss : 0.651330\n",
      "epoch 0 batch 34 d_loss : 1.154942\n",
      "epoch 0 batch 34 g_loss : 1.840123\n",
      "epoch 0 batch 35 d_loss : 1.686025\n",
      "epoch 0 batch 35 g_loss : 0.810501\n",
      "epoch 0 batch 36 d_loss : 0.738074\n",
      "epoch 0 batch 36 g_loss : 0.648629\n",
      "epoch 0 batch 37 d_loss : 0.342809\n",
      "epoch 0 batch 37 g_loss : 0.522112\n",
      "epoch 0 batch 38 d_loss : 1.174932\n",
      "epoch 0 batch 38 g_loss : 1.347859\n",
      "epoch 0 batch 39 d_loss : 0.830770\n",
      "epoch 0 batch 39 g_loss : 1.386109\n",
      "epoch 0 batch 40 d_loss : 0.398544\n",
      "epoch 0 batch 40 g_loss : 0.970521\n",
      "epoch 0 batch 41 d_loss : 0.713878\n",
      "epoch 0 batch 41 g_loss : 0.935513\n",
      "epoch 0 batch 42 d_loss : 0.980162\n",
      "epoch 0 batch 42 g_loss : 0.975253\n",
      "epoch 0 batch 43 d_loss : 0.461683\n",
      "epoch 0 batch 43 g_loss : 0.841149\n",
      "epoch 0 batch 44 d_loss : 1.419954\n",
      "epoch 0 batch 44 g_loss : 0.672836\n",
      "epoch 0 batch 45 d_loss : 0.314724\n",
      "epoch 0 batch 45 g_loss : 0.682599\n",
      "epoch 0 batch 46 d_loss : 0.998080\n",
      "epoch 0 batch 46 g_loss : 0.498137\n",
      "epoch 0 batch 47 d_loss : 0.484342\n",
      "epoch 0 batch 47 g_loss : 0.696954\n",
      "epoch 0 batch 48 d_loss : 0.559869\n",
      "epoch 0 batch 48 g_loss : 0.769998\n",
      "epoch 0 batch 49 d_loss : 0.445930\n",
      "epoch 0 batch 49 g_loss : 0.783935\n",
      "epoch 0 batch 50 d_loss : 2.994279\n",
      "epoch 0 batch 50 g_loss : 0.772982\n",
      "epoch 0 batch 51 d_loss : 0.310367\n",
      "epoch 0 batch 51 g_loss : 0.504843\n",
      "epoch 0 batch 52 d_loss : 0.930483\n",
      "epoch 0 batch 52 g_loss : 0.552365\n",
      "epoch 0 batch 53 d_loss : 0.379292\n",
      "epoch 0 batch 53 g_loss : 0.691315\n",
      "epoch 0 batch 54 d_loss : 1.051702\n",
      "epoch 0 batch 54 g_loss : 0.604403\n",
      "epoch 0 batch 55 d_loss : 0.452219\n",
      "epoch 0 batch 55 g_loss : 0.712308\n",
      "epoch 0 batch 56 d_loss : 1.811121\n",
      "epoch 0 batch 56 g_loss : 0.520386\n",
      "epoch 0 batch 57 d_loss : 0.467254\n",
      "epoch 0 batch 57 g_loss : 0.473738\n",
      "epoch 0 batch 58 d_loss : 1.723594\n",
      "epoch 0 batch 58 g_loss : 0.466156\n",
      "epoch 0 batch 59 d_loss : 0.287712\n",
      "epoch 0 batch 59 g_loss : 0.615498\n",
      "epoch 0 batch 60 d_loss : 1.246410\n",
      "epoch 0 batch 60 g_loss : 0.442883\n",
      "epoch 0 batch 61 d_loss : 0.533822\n",
      "epoch 0 batch 61 g_loss : 0.485574\n",
      "epoch 0 batch 62 d_loss : 1.328316\n",
      "epoch 0 batch 62 g_loss : 0.719351\n",
      "epoch 0 batch 63 d_loss : 0.436723\n",
      "epoch 0 batch 63 g_loss : 0.690421\n",
      "epoch 0 batch 64 d_loss : 1.598801\n",
      "epoch 0 batch 64 g_loss : 0.752793\n",
      "epoch 0 batch 65 d_loss : 0.386500\n",
      "epoch 0 batch 65 g_loss : 0.640483\n",
      "epoch 0 batch 66 d_loss : 1.652240\n",
      "epoch 0 batch 66 g_loss : 0.530372\n",
      "epoch 0 batch 67 d_loss : 0.460099\n",
      "epoch 0 batch 67 g_loss : 0.647591\n",
      "epoch 0 batch 68 d_loss : 1.728753\n",
      "epoch 0 batch 68 g_loss : 0.848213\n",
      "epoch 0 batch 69 d_loss : 0.313667\n",
      "epoch 0 batch 69 g_loss : 0.662128\n",
      "epoch 0 batch 70 d_loss : 1.804815\n",
      "epoch 0 batch 70 g_loss : 1.072309\n",
      "epoch 0 batch 71 d_loss : 0.497590\n",
      "epoch 0 batch 71 g_loss : 0.650493\n",
      "epoch 0 batch 72 d_loss : 1.529271\n",
      "epoch 0 batch 72 g_loss : 0.607959\n",
      "epoch 0 batch 73 d_loss : 0.391827\n",
      "epoch 0 batch 73 g_loss : 0.726826\n",
      "epoch 0 batch 74 d_loss : 1.861975\n",
      "epoch 0 batch 74 g_loss : 0.461549\n",
      "epoch 0 batch 75 d_loss : 0.395473\n",
      "epoch 0 batch 75 g_loss : 0.600196\n",
      "epoch 0 batch 76 d_loss : 1.292987\n",
      "epoch 0 batch 76 g_loss : 0.684390\n",
      "epoch 0 batch 77 d_loss : 0.419891\n",
      "epoch 0 batch 77 g_loss : 0.716224\n",
      "epoch 0 batch 78 d_loss : 1.828624\n",
      "epoch 0 batch 78 g_loss : 0.570323\n",
      "epoch 0 batch 79 d_loss : 0.427682\n",
      "epoch 0 batch 79 g_loss : 0.598976\n",
      "epoch 0 batch 80 d_loss : 1.606688\n",
      "epoch 0 batch 80 g_loss : 0.671870\n",
      "epoch 0 batch 81 d_loss : 0.764991\n",
      "epoch 0 batch 81 g_loss : 0.517893\n",
      "epoch 0 batch 82 d_loss : 1.258567\n",
      "epoch 0 batch 82 g_loss : 0.584759\n",
      "epoch 0 batch 83 d_loss : 0.487342\n",
      "epoch 0 batch 83 g_loss : 0.919883\n",
      "epoch 0 batch 84 d_loss : 1.239029\n",
      "epoch 0 batch 84 g_loss : 0.775807\n",
      "epoch 0 batch 85 d_loss : 0.399355\n",
      "epoch 0 batch 85 g_loss : 0.815635\n",
      "epoch 0 batch 86 d_loss : 1.822252\n",
      "epoch 0 batch 86 g_loss : 0.672009\n",
      "epoch 0 batch 87 d_loss : 0.474512\n",
      "epoch 0 batch 87 g_loss : 0.675223\n",
      "epoch 0 batch 88 d_loss : 1.740050\n",
      "epoch 0 batch 88 g_loss : 0.745874\n",
      "epoch 0 batch 89 d_loss : 0.411413\n",
      "epoch 0 batch 89 g_loss : 0.382001\n",
      "epoch 0 batch 90 d_loss : 1.612272\n",
      "epoch 0 batch 90 g_loss : 0.606039\n",
      "epoch 0 batch 91 d_loss : 0.582207\n",
      "epoch 0 batch 91 g_loss : 0.535472\n",
      "epoch 0 batch 92 d_loss : 1.528866\n",
      "epoch 0 batch 92 g_loss : 0.658043\n",
      "epoch 0 batch 93 d_loss : 0.554760\n",
      "epoch 0 batch 93 g_loss : 0.440636\n",
      "epoch 0 batch 94 d_loss : 1.372823\n",
      "epoch 0 batch 94 g_loss : 0.463212\n",
      "epoch 0 batch 95 d_loss : 0.441536\n",
      "epoch 0 batch 95 g_loss : 0.626850\n",
      "epoch 0 batch 96 d_loss : 1.063247\n",
      "epoch 0 batch 96 g_loss : 0.574925\n",
      "epoch 0 batch 97 d_loss : 0.396048\n",
      "epoch 0 batch 97 g_loss : 0.425137\n",
      "epoch 0 batch 98 d_loss : 0.312975\n",
      "epoch 0 batch 98 g_loss : 0.398090\n",
      "epoch 0 batch 99 d_loss : 0.577090\n",
      "epoch 0 batch 99 g_loss : 0.513126\n",
      "epoch 0 batch 100 d_loss : 1.499952\n",
      "epoch 0 batch 100 g_loss : 0.466778\n",
      "epoch 0 batch 101 d_loss : 0.373849\n",
      "epoch 0 batch 101 g_loss : 0.474616\n",
      "epoch 0 batch 102 d_loss : 0.334433\n",
      "epoch 0 batch 102 g_loss : 0.468742\n",
      "epoch 0 batch 103 d_loss : 0.358219\n",
      "epoch 0 batch 103 g_loss : 0.476817\n",
      "epoch 0 batch 104 d_loss : 0.616860\n",
      "epoch 0 batch 104 g_loss : 0.668691\n",
      "epoch 0 batch 105 d_loss : 0.517993\n",
      "epoch 0 batch 105 g_loss : 0.657423\n",
      "epoch 0 batch 106 d_loss : 0.876420\n",
      "epoch 0 batch 106 g_loss : 0.575367\n",
      "epoch 0 batch 107 d_loss : 0.349479\n",
      "epoch 0 batch 107 g_loss : 0.475952\n",
      "epoch 0 batch 108 d_loss : 1.019831\n",
      "epoch 0 batch 108 g_loss : 0.518209\n",
      "epoch 0 batch 109 d_loss : 0.410993\n",
      "epoch 0 batch 109 g_loss : 0.475203\n",
      "epoch 0 batch 110 d_loss : 1.017023\n",
      "epoch 0 batch 110 g_loss : 0.523634\n",
      "epoch 0 batch 111 d_loss : 0.480267\n",
      "epoch 0 batch 111 g_loss : 0.607327\n",
      "epoch 0 batch 112 d_loss : 0.650332\n",
      "epoch 0 batch 112 g_loss : 0.680198\n",
      "epoch 0 batch 113 d_loss : 0.287185\n",
      "epoch 0 batch 113 g_loss : 0.538297\n",
      "epoch 0 batch 114 d_loss : 0.392715\n",
      "epoch 0 batch 114 g_loss : 0.575125\n",
      "epoch 0 batch 115 d_loss : 0.332671\n",
      "epoch 0 batch 115 g_loss : 0.655169\n",
      "epoch 0 batch 116 d_loss : 0.396082\n",
      "epoch 0 batch 116 g_loss : 0.526130\n",
      "epoch 0 batch 117 d_loss : 0.313825\n",
      "epoch 0 batch 117 g_loss : 0.485518\n",
      "epoch 0 batch 118 d_loss : 0.418943\n",
      "epoch 0 batch 118 g_loss : 0.468061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 119 d_loss : 0.360028\n",
      "epoch 0 batch 119 g_loss : 0.475239\n",
      "epoch 0 batch 120 d_loss : 0.331618\n",
      "epoch 0 batch 120 g_loss : 0.597942\n",
      "epoch 0 batch 121 d_loss : 0.448542\n",
      "epoch 0 batch 121 g_loss : 0.632733\n",
      "epoch 0 batch 122 d_loss : 0.334933\n",
      "epoch 0 batch 122 g_loss : 0.559499\n",
      "epoch 0 batch 123 d_loss : 0.432462\n",
      "epoch 0 batch 123 g_loss : 0.423515\n",
      "epoch 0 batch 124 d_loss : 0.312176\n",
      "epoch 0 batch 124 g_loss : 0.510768\n",
      "epoch 0 batch 125 d_loss : 0.290187\n",
      "epoch 0 batch 125 g_loss : 0.416084\n",
      "epoch 0 batch 126 d_loss : 0.380018\n",
      "epoch 0 batch 126 g_loss : 0.545880\n",
      "epoch 0 batch 127 d_loss : 0.362629\n",
      "epoch 0 batch 127 g_loss : 0.610396\n",
      "epoch 0 batch 128 d_loss : 0.374493\n",
      "epoch 0 batch 128 g_loss : 0.466003\n",
      "epoch 0 batch 129 d_loss : 0.496681\n",
      "epoch 0 batch 129 g_loss : 0.667060\n",
      "epoch 0 batch 130 d_loss : 0.366042\n",
      "epoch 0 batch 130 g_loss : 0.544723\n",
      "epoch 0 batch 131 d_loss : 0.436250\n",
      "epoch 0 batch 131 g_loss : 0.531642\n",
      "epoch 0 batch 132 d_loss : 0.406847\n",
      "epoch 0 batch 132 g_loss : 0.576313\n",
      "epoch 0 batch 133 d_loss : 0.392178\n",
      "epoch 0 batch 133 g_loss : 0.634911\n",
      "epoch 0 batch 134 d_loss : 0.397937\n",
      "epoch 0 batch 134 g_loss : 0.511560\n",
      "epoch 0 batch 135 d_loss : 0.443474\n",
      "epoch 0 batch 135 g_loss : 0.469903\n",
      "epoch 0 batch 136 d_loss : 0.384198\n",
      "epoch 0 batch 136 g_loss : 0.466773\n",
      "epoch 0 batch 137 d_loss : 0.354019\n",
      "epoch 0 batch 137 g_loss : 0.437699\n",
      "epoch 0 batch 138 d_loss : 0.323879\n",
      "epoch 0 batch 138 g_loss : 0.389546\n",
      "epoch 0 batch 139 d_loss : 0.337636\n",
      "epoch 0 batch 139 g_loss : 0.415500\n",
      "epoch 0 batch 140 d_loss : 0.377820\n",
      "epoch 0 batch 140 g_loss : 0.436112\n",
      "epoch 0 batch 141 d_loss : 0.413353\n",
      "epoch 0 batch 141 g_loss : 0.494556\n",
      "epoch 0 batch 142 d_loss : 0.387445\n",
      "epoch 0 batch 142 g_loss : 0.580158\n",
      "epoch 0 batch 143 d_loss : 0.380185\n",
      "epoch 0 batch 143 g_loss : 0.441792\n",
      "epoch 0 batch 144 d_loss : 0.380534\n",
      "epoch 0 batch 144 g_loss : 0.419734\n",
      "epoch 0 batch 145 d_loss : 0.370749\n",
      "epoch 0 batch 145 g_loss : 0.465306\n",
      "epoch 0 batch 146 d_loss : 0.304389\n",
      "epoch 0 batch 146 g_loss : 0.502417\n",
      "epoch 0 batch 147 d_loss : 0.308775\n",
      "epoch 0 batch 147 g_loss : 0.546379\n",
      "epoch 0 batch 148 d_loss : 0.424545\n",
      "epoch 0 batch 148 g_loss : 0.415486\n",
      "epoch 0 batch 149 d_loss : 0.323738\n",
      "epoch 0 batch 149 g_loss : 0.409323\n",
      "epoch 0 batch 150 d_loss : 0.332845\n",
      "epoch 0 batch 150 g_loss : 0.485677\n",
      "epoch 0 batch 151 d_loss : 0.327856\n",
      "epoch 0 batch 151 g_loss : 0.487520\n",
      "epoch 0 batch 152 d_loss : 0.388738\n",
      "epoch 0 batch 152 g_loss : 0.448144\n",
      "epoch 0 batch 153 d_loss : 0.421823\n",
      "epoch 0 batch 153 g_loss : 0.403587\n",
      "epoch 0 batch 154 d_loss : 0.355929\n",
      "epoch 0 batch 154 g_loss : 0.469705\n",
      "epoch 0 batch 155 d_loss : 0.323463\n",
      "epoch 0 batch 155 g_loss : 0.497556\n",
      "epoch 0 batch 156 d_loss : 0.321079\n",
      "epoch 0 batch 156 g_loss : 0.393030\n",
      "epoch 0 batch 157 d_loss : 0.369098\n",
      "epoch 0 batch 157 g_loss : 0.491200\n",
      "epoch 0 batch 158 d_loss : 0.362307\n",
      "epoch 0 batch 158 g_loss : 0.371415\n",
      "epoch 0 batch 159 d_loss : 0.410976\n",
      "epoch 0 batch 159 g_loss : 0.469870\n",
      "epoch 0 batch 160 d_loss : 0.437231\n",
      "epoch 0 batch 160 g_loss : 0.529139\n",
      "epoch 0 batch 161 d_loss : 0.446060\n",
      "epoch 0 batch 161 g_loss : 0.516516\n",
      "epoch 0 batch 162 d_loss : 0.342666\n",
      "epoch 0 batch 162 g_loss : 0.444876\n",
      "epoch 0 batch 163 d_loss : 0.337626\n",
      "epoch 0 batch 163 g_loss : 0.390584\n",
      "epoch 0 batch 164 d_loss : 0.406525\n",
      "epoch 0 batch 164 g_loss : 0.366669\n",
      "epoch 0 batch 165 d_loss : 0.396281\n",
      "epoch 0 batch 165 g_loss : 0.453863\n",
      "epoch 0 batch 166 d_loss : 0.320920\n",
      "epoch 0 batch 166 g_loss : 0.474514\n",
      "epoch 0 batch 167 d_loss : 0.379149\n",
      "epoch 0 batch 167 g_loss : 0.382463\n",
      "epoch 0 batch 168 d_loss : 0.355400\n",
      "epoch 0 batch 168 g_loss : 0.411945\n",
      "epoch 0 batch 169 d_loss : 0.384259\n",
      "epoch 0 batch 169 g_loss : 0.399350\n",
      "epoch 0 batch 170 d_loss : 0.436951\n",
      "epoch 0 batch 170 g_loss : 0.413779\n",
      "epoch 0 batch 171 d_loss : 0.331761\n",
      "epoch 0 batch 171 g_loss : 0.412636\n",
      "epoch 0 batch 172 d_loss : 0.308126\n",
      "epoch 0 batch 172 g_loss : 0.503448\n",
      "epoch 0 batch 173 d_loss : 0.348516\n",
      "epoch 0 batch 173 g_loss : 0.533818\n",
      "epoch 0 batch 174 d_loss : 0.349034\n",
      "epoch 0 batch 174 g_loss : 0.404579\n",
      "epoch 0 batch 175 d_loss : 0.356397\n",
      "epoch 0 batch 175 g_loss : 0.508941\n",
      "epoch 0 batch 176 d_loss : 0.332624\n",
      "epoch 0 batch 176 g_loss : 0.520417\n",
      "epoch 0 batch 177 d_loss : 0.303745\n",
      "epoch 0 batch 177 g_loss : 0.479754\n",
      "epoch 0 batch 178 d_loss : 0.351760\n",
      "epoch 0 batch 178 g_loss : 0.387334\n",
      "epoch 0 batch 179 d_loss : 0.323002\n",
      "epoch 0 batch 179 g_loss : 0.456816\n",
      "epoch 0 batch 180 d_loss : 0.355909\n",
      "epoch 0 batch 180 g_loss : 0.447007\n",
      "epoch 0 batch 181 d_loss : 0.393967\n",
      "epoch 0 batch 181 g_loss : 0.495906\n",
      "epoch 0 batch 182 d_loss : 0.369063\n",
      "epoch 0 batch 182 g_loss : 0.515311\n",
      "epoch 0 batch 183 d_loss : 0.366966\n",
      "epoch 0 batch 183 g_loss : 0.389048\n",
      "epoch 0 batch 184 d_loss : 0.337358\n",
      "epoch 0 batch 184 g_loss : 0.377010\n",
      "epoch 0 batch 185 d_loss : 0.345087\n",
      "epoch 0 batch 185 g_loss : 0.437066\n",
      "epoch 0 batch 186 d_loss : 0.342520\n",
      "epoch 0 batch 186 g_loss : 0.374468\n",
      "epoch 0 batch 187 d_loss : 0.322502\n",
      "epoch 0 batch 187 g_loss : 0.472934\n",
      "epoch 0 batch 188 d_loss : 0.347627\n",
      "epoch 0 batch 188 g_loss : 0.523331\n",
      "epoch 0 batch 189 d_loss : 0.340758\n",
      "epoch 0 batch 189 g_loss : 0.513738\n",
      "epoch 0 batch 190 d_loss : 0.360870\n",
      "epoch 0 batch 190 g_loss : 0.444015\n",
      "epoch 0 batch 191 d_loss : 0.321758\n",
      "epoch 0 batch 191 g_loss : 0.456239\n",
      "epoch 0 batch 192 d_loss : 0.265406\n",
      "epoch 0 batch 192 g_loss : 0.501179\n",
      "epoch 0 batch 193 d_loss : 0.303680\n",
      "epoch 0 batch 193 g_loss : 0.503928\n",
      "epoch 0 batch 194 d_loss : 0.253716\n",
      "epoch 0 batch 194 g_loss : 0.442385\n",
      "epoch 0 batch 195 d_loss : 0.396668\n",
      "epoch 0 batch 195 g_loss : 0.625390\n",
      "epoch 0 batch 196 d_loss : 0.310382\n",
      "epoch 0 batch 196 g_loss : 0.415464\n",
      "epoch 0 batch 197 d_loss : 0.402965\n",
      "epoch 0 batch 197 g_loss : 0.526444\n",
      "epoch 0 batch 198 d_loss : 0.366619\n",
      "epoch 0 batch 198 g_loss : 0.469662\n",
      "epoch 0 batch 199 d_loss : 0.379528\n",
      "epoch 0 batch 199 g_loss : 0.425653\n",
      "epoch 0 batch 200 d_loss : 0.354037\n",
      "epoch 0 batch 200 g_loss : 0.418096\n",
      "epoch 0 batch 201 d_loss : 0.348925\n",
      "epoch 0 batch 201 g_loss : 0.546076\n",
      "epoch 0 batch 202 d_loss : 0.401183\n",
      "epoch 0 batch 202 g_loss : 0.462006\n",
      "epoch 0 batch 203 d_loss : 0.331444\n",
      "epoch 0 batch 203 g_loss : 0.503752\n",
      "epoch 0 batch 204 d_loss : 0.333293\n",
      "epoch 0 batch 204 g_loss : 0.461054\n",
      "epoch 0 batch 205 d_loss : 0.373423\n",
      "epoch 0 batch 205 g_loss : 0.425237\n",
      "epoch 0 batch 206 d_loss : 0.321767\n",
      "epoch 0 batch 206 g_loss : 0.334261\n",
      "epoch 0 batch 207 d_loss : 0.279813\n",
      "epoch 0 batch 207 g_loss : 0.412047\n",
      "epoch 0 batch 208 d_loss : 0.336225\n",
      "epoch 0 batch 208 g_loss : 0.486605\n",
      "epoch 0 batch 209 d_loss : 0.367365\n",
      "epoch 0 batch 209 g_loss : 0.498926\n",
      "epoch 0 batch 210 d_loss : 0.350474\n",
      "epoch 0 batch 210 g_loss : 0.365501\n",
      "epoch 0 batch 211 d_loss : 0.364807\n",
      "epoch 0 batch 211 g_loss : 0.391881\n",
      "epoch 0 batch 212 d_loss : 0.289195\n",
      "epoch 0 batch 212 g_loss : 0.437470\n",
      "epoch 0 batch 213 d_loss : 0.345773\n",
      "epoch 0 batch 213 g_loss : 0.451022\n",
      "epoch 0 batch 214 d_loss : 0.380476\n",
      "epoch 0 batch 214 g_loss : 0.441491\n",
      "epoch 0 batch 215 d_loss : 0.315987\n",
      "epoch 0 batch 215 g_loss : 0.398283\n",
      "epoch 0 batch 216 d_loss : 0.344230\n",
      "epoch 0 batch 216 g_loss : 0.477602\n",
      "epoch 0 batch 217 d_loss : 0.325979\n",
      "epoch 0 batch 217 g_loss : 0.490358\n",
      "epoch 0 batch 218 d_loss : 0.450151\n",
      "epoch 0 batch 218 g_loss : 0.416822\n",
      "epoch 0 batch 219 d_loss : 0.380045\n",
      "epoch 0 batch 219 g_loss : 0.453746\n",
      "epoch 0 batch 220 d_loss : 0.326118\n",
      "epoch 0 batch 220 g_loss : 0.468921\n",
      "epoch 0 batch 221 d_loss : 0.298568\n",
      "epoch 0 batch 221 g_loss : 0.421698\n",
      "epoch 0 batch 222 d_loss : 0.336244\n",
      "epoch 0 batch 222 g_loss : 0.430839\n",
      "epoch 0 batch 223 d_loss : 0.314655\n",
      "epoch 0 batch 223 g_loss : 0.485121\n",
      "epoch 0 batch 224 d_loss : 0.355145\n",
      "epoch 0 batch 224 g_loss : 0.477177\n",
      "epoch 0 batch 225 d_loss : 0.341168\n",
      "epoch 0 batch 225 g_loss : 0.403329\n",
      "epoch 0 batch 226 d_loss : 0.318486\n",
      "epoch 0 batch 226 g_loss : 0.503233\n",
      "epoch 0 batch 227 d_loss : 0.371800\n",
      "epoch 0 batch 227 g_loss : 0.525591\n",
      "epoch 0 batch 228 d_loss : 0.345107\n",
      "epoch 0 batch 228 g_loss : 0.415664\n",
      "epoch 0 batch 229 d_loss : 0.365972\n",
      "epoch 0 batch 229 g_loss : 0.464885\n",
      "epoch 0 batch 230 d_loss : 0.356513\n",
      "epoch 0 batch 230 g_loss : 0.556167\n",
      "epoch 0 batch 231 d_loss : 0.389892\n",
      "epoch 0 batch 231 g_loss : 0.465604\n",
      "epoch 0 batch 232 d_loss : 0.412330\n",
      "epoch 0 batch 232 g_loss : 0.358472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 233 d_loss : 0.384767\n",
      "epoch 0 batch 233 g_loss : 0.511478\n",
      "epoch 0 batch 234 d_loss : 0.318527\n",
      "epoch 0 batch 234 g_loss : 0.455358\n",
      "epoch 0 batch 235 d_loss : 0.361590\n",
      "epoch 0 batch 235 g_loss : 0.440838\n",
      "epoch 0 batch 236 d_loss : 0.332525\n",
      "epoch 0 batch 236 g_loss : 0.455800\n",
      "epoch 0 batch 237 d_loss : 0.349816\n",
      "epoch 0 batch 237 g_loss : 0.405976\n",
      "epoch 0 batch 238 d_loss : 0.355179\n",
      "epoch 0 batch 238 g_loss : 0.437939\n",
      "epoch 0 batch 239 d_loss : 0.341172\n",
      "epoch 0 batch 239 g_loss : 0.425106\n",
      "epoch 0 batch 240 d_loss : 0.259941\n",
      "epoch 0 batch 240 g_loss : 0.467467\n",
      "epoch 0 batch 241 d_loss : 0.346637\n",
      "epoch 0 batch 241 g_loss : 0.406927\n",
      "epoch 0 batch 242 d_loss : 0.348409\n",
      "epoch 0 batch 242 g_loss : 0.405305\n",
      "epoch 0 batch 243 d_loss : 0.372341\n",
      "epoch 0 batch 243 g_loss : 0.446771\n",
      "epoch 0 batch 244 d_loss : 0.292736\n",
      "epoch 0 batch 244 g_loss : 0.416150\n",
      "epoch 0 batch 245 d_loss : 0.295105\n",
      "epoch 0 batch 245 g_loss : 0.505306\n",
      "epoch 0 batch 246 d_loss : 0.308373\n",
      "epoch 0 batch 246 g_loss : 0.518912\n",
      "epoch 0 batch 247 d_loss : 0.320246\n",
      "epoch 0 batch 247 g_loss : 0.468353\n",
      "epoch 0 batch 248 d_loss : 0.303249\n",
      "epoch 0 batch 248 g_loss : 0.643151\n",
      "epoch 0 batch 249 d_loss : 0.368051\n",
      "epoch 0 batch 249 g_loss : 0.491159\n",
      "epoch 0 batch 250 d_loss : 0.399993\n",
      "epoch 0 batch 250 g_loss : 0.414869\n",
      "epoch 0 batch 251 d_loss : 0.314110\n",
      "epoch 0 batch 251 g_loss : 0.367027\n",
      "epoch 0 batch 252 d_loss : 0.290355\n",
      "epoch 0 batch 252 g_loss : 0.339632\n",
      "epoch 0 batch 253 d_loss : 0.317057\n",
      "epoch 0 batch 253 g_loss : 0.511931\n",
      "epoch 0 batch 254 d_loss : 0.364837\n",
      "epoch 0 batch 254 g_loss : 0.399777\n",
      "epoch 0 batch 255 d_loss : 0.423231\n",
      "epoch 0 batch 255 g_loss : 0.375935\n",
      "epoch 0 batch 256 d_loss : 0.373018\n",
      "epoch 0 batch 256 g_loss : 0.622562\n",
      "epoch 0 batch 257 d_loss : 0.464433\n",
      "epoch 0 batch 257 g_loss : 0.467718\n",
      "epoch 0 batch 258 d_loss : 0.261740\n",
      "epoch 0 batch 258 g_loss : 0.483704\n",
      "epoch 0 batch 259 d_loss : 0.383038\n",
      "epoch 0 batch 259 g_loss : 0.490514\n",
      "epoch 0 batch 260 d_loss : 0.266778\n",
      "epoch 0 batch 260 g_loss : 0.458359\n",
      "epoch 0 batch 261 d_loss : 0.260838\n",
      "epoch 0 batch 261 g_loss : 0.500729\n",
      "epoch 0 batch 262 d_loss : 0.395841\n",
      "epoch 0 batch 262 g_loss : 0.352976\n",
      "epoch 0 batch 263 d_loss : 0.352314\n",
      "epoch 0 batch 263 g_loss : 0.523387\n",
      "epoch 0 batch 264 d_loss : 0.298637\n",
      "epoch 0 batch 264 g_loss : 0.506068\n",
      "epoch 0 batch 265 d_loss : 0.319924\n",
      "epoch 0 batch 265 g_loss : 0.580308\n",
      "epoch 0 batch 266 d_loss : 0.317055\n",
      "epoch 0 batch 266 g_loss : 0.524323\n",
      "epoch 0 batch 267 d_loss : 0.349616\n",
      "epoch 0 batch 267 g_loss : 0.426722\n",
      "epoch 0 batch 268 d_loss : 0.314127\n",
      "epoch 0 batch 268 g_loss : 0.449734\n",
      "epoch 0 batch 269 d_loss : 0.373800\n",
      "epoch 0 batch 269 g_loss : 0.564881\n",
      "epoch 0 batch 270 d_loss : 0.388292\n",
      "epoch 0 batch 270 g_loss : 0.484317\n",
      "epoch 0 batch 271 d_loss : 0.324346\n",
      "epoch 0 batch 271 g_loss : 0.400493\n",
      "epoch 0 batch 272 d_loss : 0.359414\n",
      "epoch 0 batch 272 g_loss : 0.525058\n",
      "epoch 0 batch 273 d_loss : 0.271638\n",
      "epoch 0 batch 273 g_loss : 0.481035\n",
      "epoch 0 batch 274 d_loss : 0.338070\n",
      "epoch 0 batch 274 g_loss : 0.502758\n",
      "epoch 0 batch 275 d_loss : 0.408187\n",
      "epoch 0 batch 275 g_loss : 0.424462\n",
      "epoch 0 batch 276 d_loss : 0.381268\n",
      "epoch 0 batch 276 g_loss : 0.438455\n",
      "epoch 0 batch 277 d_loss : 0.375434\n",
      "epoch 0 batch 277 g_loss : 0.431189\n",
      "epoch 0 batch 278 d_loss : 0.364523\n",
      "epoch 0 batch 278 g_loss : 0.455022\n",
      "epoch 0 batch 279 d_loss : 0.298991\n",
      "epoch 0 batch 279 g_loss : 0.475158\n",
      "epoch 0 batch 280 d_loss : 0.310035\n",
      "epoch 0 batch 280 g_loss : 0.456982\n",
      "epoch 0 batch 281 d_loss : 0.332146\n",
      "epoch 0 batch 281 g_loss : 0.402603\n",
      "epoch 0 batch 282 d_loss : 0.415078\n",
      "epoch 0 batch 282 g_loss : 0.421493\n",
      "epoch 0 batch 283 d_loss : 0.334328\n",
      "epoch 0 batch 283 g_loss : 0.495124\n",
      "epoch 0 batch 284 d_loss : 0.325526\n",
      "epoch 0 batch 284 g_loss : 0.593567\n",
      "epoch 0 batch 285 d_loss : 0.344355\n",
      "epoch 0 batch 285 g_loss : 0.500513\n",
      "epoch 0 batch 286 d_loss : 0.346935\n",
      "epoch 0 batch 286 g_loss : 0.422479\n",
      "epoch 0 batch 287 d_loss : 0.325179\n",
      "epoch 0 batch 287 g_loss : 0.448512\n",
      "epoch 0 batch 288 d_loss : 0.367819\n",
      "epoch 0 batch 288 g_loss : 0.468803\n",
      "epoch 0 batch 289 d_loss : 0.225103\n",
      "epoch 0 batch 289 g_loss : 0.498543\n",
      "epoch 0 batch 290 d_loss : 0.391045\n",
      "epoch 0 batch 290 g_loss : 0.449838\n",
      "epoch 0 batch 291 d_loss : 0.323781\n",
      "epoch 0 batch 291 g_loss : 0.427571\n",
      "epoch 0 batch 292 d_loss : 0.326359\n",
      "epoch 0 batch 292 g_loss : 0.361092\n",
      "epoch 0 batch 293 d_loss : 0.432974\n",
      "epoch 0 batch 293 g_loss : 0.452482\n",
      "epoch 0 batch 294 d_loss : 0.372927\n",
      "epoch 0 batch 294 g_loss : 0.526239\n",
      "epoch 0 batch 295 d_loss : 0.338969\n",
      "epoch 0 batch 295 g_loss : 0.449666\n",
      "epoch 0 batch 296 d_loss : 0.401258\n",
      "epoch 0 batch 296 g_loss : 0.509952\n",
      "epoch 0 batch 297 d_loss : 0.401796\n",
      "epoch 0 batch 297 g_loss : 0.420007\n",
      "epoch 0 batch 298 d_loss : 0.403150\n",
      "epoch 0 batch 298 g_loss : 0.411756\n",
      "epoch 0 batch 299 d_loss : 0.306661\n",
      "epoch 0 batch 299 g_loss : 0.415600\n",
      "epoch 0 batch 300 d_loss : 0.369550\n",
      "epoch 0 batch 300 g_loss : 0.460312\n",
      "epoch 0 batch 301 d_loss : 0.357241\n",
      "epoch 0 batch 301 g_loss : 0.548455\n",
      "epoch 0 batch 302 d_loss : 0.375692\n",
      "epoch 0 batch 302 g_loss : 0.410897\n",
      "epoch 0 batch 303 d_loss : 0.264236\n",
      "epoch 0 batch 303 g_loss : 0.473621\n",
      "epoch 0 batch 304 d_loss : 0.313337\n",
      "epoch 0 batch 304 g_loss : 0.345697\n",
      "epoch 0 batch 305 d_loss : 0.385142\n",
      "epoch 0 batch 305 g_loss : 0.504196\n",
      "epoch 0 batch 306 d_loss : 0.283254\n",
      "epoch 0 batch 306 g_loss : 0.595361\n",
      "epoch 0 batch 307 d_loss : 0.363675\n",
      "epoch 0 batch 307 g_loss : 0.589216\n",
      "epoch 0 batch 308 d_loss : 0.390034\n",
      "epoch 0 batch 308 g_loss : 0.436605\n",
      "epoch 0 batch 309 d_loss : 0.395892\n",
      "epoch 0 batch 309 g_loss : 0.392250\n"
     ]
    }
   ],
   "source": [
    "train_another(1000, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_moment = datetime.now()\n",
    "\n",
    "day, month = str(current_moment.day), str(current_moment.month)\n",
    "hour, minute = str(current_moment.hour), str(current_moment.minute)\n",
    "\n",
    "with open(os.getcwd() + '/Changes.txt', 'a') as f:\n",
    "    clock =  (day + '.' + month + '    ' + hour + ':' + minute)\n",
    "    f.write(clock + '...........g_optim -> 0.0003, d_optim->0.0004' + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
